"""
AIæ±‚äººãƒãƒƒãƒãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ  v2.0
- å‹•çš„è³ªå•ç”Ÿæˆï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿é§†å‹•ï¼‰
- ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° + ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹ï¼‰
- å¤šè»¸è©•ä¾¡ï¼ˆä¼æ¥­æ–‡åŒ–ã€åƒãæ–¹ã€ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ï¼‰
- ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•è¿½è·¡ï¼ˆã‚¯ãƒªãƒƒã‚¯ã€ãŠæ°—ã«å…¥ã‚Šã€å¿œå‹Ÿï¼‰
"""

from flask import Flask, request, render_template, redirect, url_for, session, jsonify
import psycopg2
from psycopg2.extras import RealDictCursor
from werkzeug.security import generate_password_hash, check_password_hash
from datetime import datetime
import openai
import uuid
import json
from typing import List, Dict, Any, Optional
from openai import OpenAI
import os
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# æ–°ã—ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from tracking import UserInteractionTracker, ChatHistoryManager, QuestionResponseManager
from multi_axis_evaluator import JobAttributeExtractor, UserPreferenceManager
from dynamic_questions import QuestionGenerator, QuestionSelector
from hybrid_recommender import HybridRecommender, MLModelScorer
from dynamic_question_generator_v2 import DynamicQuestionGenerator

app = Flask(__name__)
app.secret_key = "supersecretkey"

# OpenAI APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("OPENAI_API_KEY ãŒ .env ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

client = OpenAI(api_key=openai_api_key)

# å‹•çš„è³ªå•ç”Ÿæˆå™¨ã®åˆæœŸåŒ–
dynamic_question_gen = DynamicQuestionGenerator(client)

# --- DBæ¥ç¶š ---
def get_db_conn():
    return psycopg2.connect(
        host="localhost", port=5432, dbname="jobmatch",
        user="devuser", password="devpass"
    )


# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ç”Ÿæˆ ---
def get_or_create_session_id():
    """ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’å–å¾—ã¾ãŸã¯ç”Ÿæˆ"""
    if 'chat_session_id' not in session:
        session['chat_session_id'] = str(uuid.uuid4())
    return session['chat_session_id']


# --- ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ ---
@app.route("/")
def index():
    return redirect(url_for("step1"))


# --- Step1: å€‹äººæƒ…å ±ç™»éŒ² ---
@app.route("/step1", methods=["GET", "POST"])
def step1():
    if request.method == "POST":
        user_name = request.form["name"]
        email = request.form["email"]
        password_hash = generate_password_hash(request.form["password"])
        birth_day = request.form.get("birth_day")
        phone_number = request.form.get("phone_number")
        address = request.form.get("address")

        conn = get_db_conn()
        cur = conn.cursor()

        # â˜…â˜…â˜… æœ€å¤§user_id + 1ã‚’å–å¾— â˜…â˜…â˜…
        cur.execute("SELECT COALESCE(MAX(user_id), 0) + 1 FROM personal_date")
        new_user_id = cur.fetchone()[0]

        cur.execute("""
            INSERT INTO personal_date (user_id, email, password_hash, user_name, birth_day, phone_number, address, created_at, updated_at)
            VALUES (%s, %s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
        """, (new_user_id, email, password_hash, user_name, birth_day, phone_number, address))

        cur.execute("""
            INSERT INTO user_profile (user_id, job_title, location_prefecture, salary_min, created_at, updated_at)
            VALUES (%s, '', '', 0, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
        """, (new_user_id,))

        conn.commit()
        cur.close()
        conn.close()

        session["user_id"] = new_user_id
        return redirect(url_for("step2"))

    return render_template("form_step1.html")


# --- Step2: å¸Œæœ›æ¡ä»¶å…¥åŠ› ---
@app.route("/step2", methods=["GET", "POST"])
def step2():
    if request.method == "POST":
        job_title = request.form.get("job_title")
        location_prefecture = request.form.get("location_prefecture")
        salary_min = request.form.get("salary_min")

        conn = get_db_conn()
        cur = conn.cursor()
        cur.execute("""
            UPDATE user_profile
            SET job_title = %s,
                location_prefecture = %s,
                salary_min = %s,
                updated_at = CURRENT_TIMESTAMP
            WHERE user_id = %s
        """, (job_title, location_prefecture, salary_min, session["user_id"]))
        conn.commit()
        cur.close()
        conn.close()

        return redirect(url_for("chat_page"))

    return render_template("form_step2.html")


# --- ãƒ­ã‚°ã‚¤ãƒ³ ---
@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        identifier = request.form["identifier"]
        password = request.form["password"]

        conn = get_db_conn()
        cur = conn.cursor()
        cur.execute("SELECT user_id, email, password_hash FROM Personal_data WHERE email=%s OR user_name=%s",
                    (identifier, identifier))
        user = cur.fetchone()
        cur.close()
        conn.close()

        if user and check_password_hash(user[2], password):
            session["user_id"] = user[0]
            return redirect(url_for("chat_page"))
        else:
            return "ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—ã—ã¾ã—ãŸ"

    return render_template("login.html")


# --- ãƒãƒ£ãƒƒãƒˆç”»é¢ ---
@app.route("/chat")
def chat_page():
    """ãƒãƒ£ãƒƒãƒˆç”»é¢"""
    if 'user_id' not in session:
        return redirect(url_for('index'))

    user_id = session['user_id']
    session_id = get_or_create_session_id()

    # â˜…â˜…â˜… æ¨è–¦ã‚’å–å¾—ï¼ˆ1å›ã ã‘å®Ÿè¡Œï¼‰ â˜…â˜…â˜…
    # ä¸Šé™ãªã—ï¼šè©²å½“ã™ã‚‹å…¨ã¦ã®æ±‚äººã‚’å–å¾—
    recommendations = HybridRecommender.get_hybrid_recommendations(user_id, top_k=None, previous_job_ids=None)

    count = len(recommendations)
    print(f"Initial recommendations: {count} jobs")

    # â˜…â˜…â˜… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«åˆå›ã®çµæœã‚’ä¿å­˜ â˜…â˜…â˜…
    initial_job_ids = [str(job['id']) for job in recommendations]
    save_filtered_job_ids_to_db(user_id, session_id, initial_job_ids)

    if count == 0:
        initial_message = "æ¡ä»¶ã«åˆã†æ±‚äººãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¡ä»¶ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚"
    elif count <= 3:
        # â˜…â˜…â˜… 3ä»¶ä»¥ä¸‹ãªã‚‰æœ€çµ‚æ®µéšï¼ˆã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚° + é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼æ±‚äººã‚’å«ã‚€ï¼‰ â˜…â˜…â˜…
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¼šè©±å±¥æ­´ã‚’ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åŒ–
        update_user_conversation_embedding(user_id)
        
        # çµã‚Šè¾¼ã‚“ã æ±‚äººã®IDã‚’è¨˜éŒ²
        displayed_ids = [str(job['id']) for job in recommendations]
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ¤œç´¢ã§è¿½åŠ ã®2ä»¶ã‚’å–å¾—
        best_matches = find_best_matches_with_embeddings(
            user_id, 
            filtered_jobs=None,
            top_k=2,
            exclude_ids=displayed_ids
        )
        
        # é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿œå‹Ÿæ¸ˆã¿æ±‚äººã‚’1ä»¶å–å¾—
        similar_user_job = find_similar_user_applied_job(user_id)
        
        # å…¨æ±‚äººã‚’çµåˆ
        all_jobs = recommendations + best_matches
        if similar_user_job:
            all_jobs.append(similar_user_job)
        
        # GPT-4ã§èª¬æ˜æ–‡ã‚’ç”Ÿæˆ
        explanation = generate_final_recommendation_with_gpt(user_id, all_jobs)
        
        # çµã‚Šè¾¼ã‚“ã æ±‚äººã‚’æ•´å½¢
        filtered_details = []
        for i, job in enumerate(recommendations, 1):
            detail = (
                f"ğŸ¯ çµã‚Šè¾¼ã¿å€™è£œ{i}: {job['company_name']} / {job['job_title']}\n"
                f"ğŸ“ {job['location_prefecture']}\n"
                f"ğŸ’° å¹´å: {job['salary_min']}ä¸‡ã€œ{job['salary_max']}ä¸‡"
            )
            filtered_details.append(detail)
        
        # AIæ¨è–¦ã‚’æ•´å½¢
        additional_details = []
        if best_matches and len(best_matches) > 0:
            for i, job in enumerate(best_matches, 1):
                detail = (
                    f"â­ AIãŠã™ã™ã‚{i}: {job['company_name']} / {job['job_title']}\n"
                    f"ğŸ“ {job['location_prefecture']}\n"
                    f"ğŸ’° å¹´å: {job['salary_min']}ä¸‡ã€œ{job['salary_max']}ä¸‡\n"
                    f"ğŸ¯ ãƒãƒƒãƒåº¦: {job['similarity']:.1%}"
                )
                additional_details.append(detail)
        
        # é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿œå‹Ÿæ±‚äººã‚’æ•´å½¢
        similar_user_detail = None
        if similar_user_job:
            similar_text = generate_similar_user_recommendation_text(user_id, similar_user_job)
            similar_user_detail = (
                f"{similar_text}\n\n"
                f"ğŸ’¼ {similar_user_job['company_name']} / {similar_user_job['job_title']}\n"
                f"ğŸ“ {similar_user_job['location_prefecture']}\n"
                f"ğŸ’° å¹´å: {similar_user_job['salary_min']}ä¸‡ã€œ{similar_user_job['salary_max']}ä¸‡\n"
                f"ğŸ‘¥ é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ {similar_user_job['apply_count']}äººãŒå¿œå‹Ÿ"
            )
        
        # æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’çµ„ã¿ç«‹ã¦
        total_count = len(recommendations) + len(best_matches) + (1 if similar_user_job else 0)
        
        initial_message = f"{explanation}\n\n"
        initial_message += f"ã€çµã‚Šè¾¼ã‚“ã å€™è£œï¼ˆ{len(recommendations)}ä»¶ï¼‰ã€‘\n\n"
        initial_message += "\n\n".join(filtered_details)
        
        if additional_details:
            initial_message += f"\n\nã€AIãŒé¸ã‚“ã è¿½åŠ ã®ãŠã™ã™ã‚ï¼ˆ{len(best_matches)}ä»¶ï¼‰ã€‘\n\n"
            initial_message += "\n\n".join(additional_details)
        
        if similar_user_detail:
            initial_message += f"\n\nã€é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¿œå‹Ÿã—ãŸæ±‚äººã€‘\n\n"
            initial_message += similar_user_detail
        
        initial_message += f"\n\nâœ¨ åˆè¨ˆ {total_count} ä»¶ã®æ±‚äººã‚’ã”ç´¹ä»‹ã—ã¾ã—ãŸã€‚"
        
    else:
        # â˜…â˜…â˜… 4ä»¶ä»¥ä¸Šãªã‚‰å®Œå…¨å‹•çš„ã«è³ªå•ã‚’ç”Ÿæˆ â˜…â˜…â˜…
        next_question = dynamic_question_gen.generate_next_question(user_id, recommendations, "")
        
        if next_question:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è³ªå•æƒ…å ±ã‚’ä¿å­˜
            session['last_question_key'] = next_question['question_key']
            session['last_question_text'] = next_question['question_text']
            session['last_question_category'] = next_question.get('category', 'åƒãæ–¹ã®æŸ”è»Ÿæ€§')
            
            initial_message = f"ã‚ãªãŸã«ãƒãƒƒãƒã™ã‚‹æ±‚äººãŒ {count} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚\n\n{next_question['question_text']}"
        else:
            initial_message = f"ã‚ãªãŸã«ãƒãƒƒãƒã™ã‚‹æ±‚äººãŒ {count} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚\n\næ¡ä»¶ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚"

    # åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«ä¿å­˜
    ChatHistoryManager.save_message(user_id, 'bot', initial_message, session_id=session_id)

    return render_template('chat.html', initial_message=initial_message)

def generate_embedding(text: str) -> List[float]:
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åŒ–"""
    try:
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"Error generating embedding: {e}")
        return None


def find_best_matches_with_embeddings(user_id: int, filtered_jobs: List[Dict] = None, top_k: int = 2, exclude_ids: List[str] = None) -> List[Dict[str, Any]]:
    """
    ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ¤œç´¢ã§æœ€ã‚‚ãƒãƒƒãƒã™ã‚‹æ±‚äººã‚’è¦‹ã¤ã‘ã‚‹
    
    Args:
        user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        filtered_jobs: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ã®æ±‚äººãƒªã‚¹ãƒˆï¼ˆNoneã®å ´åˆã¯å…¨æ±‚äººã‹ã‚‰æ¤œç´¢ï¼‰
        top_k: ä¸Šä½Kä»¶ã‚’è¿”ã™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ2ä»¶ï¼‰
        exclude_ids: é™¤å¤–ã™ã‚‹æ±‚äººIDã®ãƒªã‚¹ãƒˆ
    
    Returns:
        ãƒãƒƒãƒã—ãŸæ±‚äººã®ãƒªã‚¹ãƒˆ
    """
    try:
        conn = get_db_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        cur.execute("""
            SELECT job_title, location_prefecture, salary_min
            FROM user_profile
            WHERE user_id = %s
        """, (user_id,))
        
        profile = cur.fetchone()
        
        if not profile:
            cur.close()
            conn.close()
            return []
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•å›ç­”ã‚’å–å¾—
        cur.execute("""
            SELECT dq.question_text, uqr.response_text
            FROM user_question_responses uqr
            JOIN dynamic_questions dq ON uqr.question_id = dq.id
            WHERE uqr.user_id = %s
            ORDER BY uqr.created_at
        """, (user_id,))
        
        responses = cur.fetchall()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¡ä»¶ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        user_text = f"""
è·ç¨®: {profile['job_title']}
å‹¤å‹™åœ°: {profile['location_prefecture']}
å¸Œæœ›å¹´å: {profile['salary_min']}ä¸‡å††ä»¥ä¸Š

ã€å¸Œæœ›æ¡ä»¶ã€‘
"""
        
        for resp in responses:
            user_text += f"- {resp['question_text']}: {resp['response_text']}\n"
        
        print(f"\n=== User Preference Text ===\n{user_text}\n")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¡ä»¶ã‚’ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åŒ–
        user_embedding = generate_embedding(user_text)
        
        if user_embedding is None:
            cur.close()
            conn.close()
            return []
        
        # â˜…â˜…â˜… å…¨æ±‚äººã‹ã‚‰æ¤œç´¢ï¼ˆexclude_idsé™¤å¤–ï¼‰ â˜…â˜…â˜…
        exclude_clause = ""
        params = [f"%{profile['job_title']}%", f"%{profile['location_prefecture']}%", profile['salary_min']]
        
        if exclude_ids:
            exclude_clause = "AND cp.id::text != ALL(%s)"
            params.append(exclude_ids)
        
        cur.execute(f"""
            SELECT cp.id, cp.job_title, cp.location_prefecture,
                   cp.salary_min, cp.salary_max,
                   cd.company_name,
                   ja.company_culture, ja.work_flexibility, ja.career_path
            FROM company_profile cp
            JOIN company_date cd ON cp.company_id = cd.company_id
            LEFT JOIN job_attributes ja ON cp.id::text = ja.job_id::text
            WHERE cp.job_title ILIKE %s
              AND cp.location_prefecture ILIKE %s
              AND cp.salary_min >= %s
              {exclude_clause}
            LIMIT 100
        """, params)
        
        jobs = cur.fetchall()
        
        cur.close()
        conn.close()
        
        print(f"Found {len(jobs)} jobs for embedding comparison")
        
        if not jobs:
            return []
        
        # å„æ±‚äººã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ã¦ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åŒ–
        job_similarities = []
        
        for job in jobs:
            # æ±‚äººãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
            job_text = f"""
è·ç¨®: {job['job_title']}
ä¼æ¥­: {job['company_name']}
å‹¤å‹™åœ°: {job['location_prefecture']}
å¹´å: {job['salary_min']}ä¸‡ã€œ{job['salary_max']}ä¸‡å††
"""
            
            if job.get('work_flexibility'):
                wf = job['work_flexibility']
                job_text += f"\nã€åƒãæ–¹ã€‘\n"
                job_text += f"- ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯: {'å¯èƒ½' if wf.get('remote') else 'ä¸å¯'}\n"
                job_text += f"- ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ : {'ã‚ã‚Š' if wf.get('flex_time') else 'ãªã—'}\n"
                job_text += f"- å‰¯æ¥­: {'å¯èƒ½' if wf.get('side_job') else 'ä¸å¯'}\n"
                job_text += f"- æ®‹æ¥­: {wf.get('overtime', 'ä¸æ˜')}\n"
            
            if job.get('company_culture'):
                cc = job['company_culture']
                job_text += f"\nã€ä¼æ¥­æ–‡åŒ–ã€‘\n"
                job_text += f"- è¦æ¨¡: {cc.get('size', 'ä¸æ˜')}\n"
                job_text += f"- é›°å›²æ°—: {cc.get('atmosphere', 'ä¸æ˜')}\n"
            
            if job.get('career_path'):
                cp_data = job['career_path']
                job_text += f"\nã€ã‚­ãƒ£ãƒªã‚¢ã€‘\n"
                job_text += f"- æˆé•·æ©Ÿä¼š: {'ã‚ã‚Š' if cp_data.get('growth_opportunities') else 'ãªã—'}\n"
                job_text += f"- ç ”ä¿®: {'å……å®Ÿ' if cp_data.get('training') else 'å°‘ãªã„'}\n"
                job_text += f"- æ˜‡é€²ã‚¹ãƒ”ãƒ¼ãƒ‰: {cp_data.get('promotion_speed', 'ä¸æ˜')}\n"
            
            # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åŒ–
            job_embedding = generate_embedding(job_text)
            
            if job_embedding is None:
                continue
            
            # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
            similarity = cosine_similarity(
                [user_embedding],
                [job_embedding]
            )[0][0]
            
            job_similarities.append({
                'id': job['id'],
                'job_title': job['job_title'],
                'company_name': job['company_name'],
                'location_prefecture': job['location_prefecture'],
                'salary_min': job['salary_min'],
                'salary_max': job['salary_max'],
                'similarity': float(similarity)
            })
        
        # é¡ä¼¼åº¦ã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
        job_similarities.sort(key=lambda x: x['similarity'], reverse=True)
        
        print(f"\n=== Top {top_k} Matches by Embedding ===")
        for i, job in enumerate(job_similarities[:top_k], 1):
            print(f"{i}. {job['job_title']} at {job['company_name']} - Similarity: {job['similarity']:.4f}")
        
        return job_similarities[:top_k]
        
    except Exception as e:
        print(f"Error finding best matches with embeddings: {e}")
        import traceback
        traceback.print_exc()
        return []


def generate_final_recommendation_with_gpt(user_id: int, matched_jobs: List[Dict]) -> str:
    """
    GPT-4ã§æœ€çµ‚ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ–‡ã‚’ç”Ÿæˆ
    
    Args:
        user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        matched_jobs: ãƒãƒƒãƒã—ãŸæ±‚äººãƒªã‚¹ãƒˆï¼ˆçµã‚Šè¾¼ã¿+AIæ¨è–¦ã®å…¨ã¦ï¼‰
    
    Returns:
        èª¬æ˜æ–‡
    """
    try:
        conn = get_db_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”å±¥æ­´ã‚’å–å¾—
        cur.execute("""
            SELECT dq.question_text, uqr.response_text
            FROM user_question_responses uqr
            JOIN dynamic_questions dq ON uqr.question_id = dq.id
            WHERE uqr.user_id = %s
            ORDER BY uqr.created_at
        """, (user_id,))
        
        responses = cur.fetchall()
        
        cur.close()
        conn.close()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¡ä»¶ã‚’æ•´ç†
        conditions_text = "\n".join([
            f"- {resp['question_text']}: {resp['response_text']}"
            for resp in responses
        ])
        
        # æ±‚äººæƒ…å ±ã‚’æ•´ç†
        jobs_text = ""
        for i, job in enumerate(matched_jobs, 1):
            jobs_text += f"\n{i}. {job['company_name']} / {job['job_title']}\n"
            jobs_text += f"   å¹´å: {job['salary_min']}ä¸‡ã€œ{job['salary_max']}ä¸‡\n"
            if 'similarity' in job:
                jobs_text += f"   ãƒãƒƒãƒåº¦: {job['similarity']:.1%}\n"
        
        prompt = f"""
ã‚ãªãŸã¯æ±‚äººãƒãƒƒãƒãƒ³ã‚°AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¸Œæœ›æ¡ä»¶ã«åŸºã¥ã„ã¦ã€æœ€ã‚‚ãƒãƒƒãƒã™ã‚‹æ±‚äººã‚’å³é¸ã—ã¾ã—ãŸã€‚

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¸Œæœ›æ¡ä»¶ã€‘
{conditions_text}

ã€å³é¸ã—ãŸæ±‚äººã€‘
{jobs_text}

ã€ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯ã€‘
ä¸Šè¨˜ã®æ±‚äººãŒãªãœãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãƒãƒƒãƒã™ã‚‹ã®ã‹ã€æ¸©ã‹ã¿ã®ã‚ã‚‹æ–‡ç« ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
1. å°å…¥æ–‡ï¼ˆã€Œã‚ãªãŸã®å¸Œæœ›ã«æœ€ã‚‚ãƒãƒƒãƒã™ã‚‹æ±‚äººã‚’å³é¸ã—ã¾ã—ãŸã€ãªã©ï¼‰
2. æ±‚äººã®é­…åŠ›ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¡ä»¶ã¨ã®ä¸€è‡´ç‚¹ï¼‰
3. å‰å‘ããªç· ã‚ããã‚Š

è‡ªç„¶ã§è¦ªã—ã¿ã‚„ã™ã„ãƒˆãƒ¼ãƒ³ã§ã€3ã€œ5æ–‡ç¨‹åº¦ã§æ›¸ã„ã¦ãã ã•ã„ã€‚
"""
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.8,
            max_tokens=300
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        print(f"Error generating final recommendation: {e}")
        return "ã‚ãªãŸã®å¸Œæœ›æ¡ä»¶ã«æœ€ã‚‚ãƒãƒƒãƒã™ã‚‹æ±‚äººã‚’å³é¸ã—ã¾ã—ãŸã€‚"
    
def save_filtered_job_ids_to_db(user_id: int, session_id: str, job_ids: List[str]):
    """ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
    try:
        conn = get_db_conn()
        cur = conn.cursor()
        
        # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
        cur.execute("""
            DELETE FROM user_filtered_jobs
            WHERE user_id = %s AND session_id = %s
        """, (user_id, session_id))
        
        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ï¼ˆãƒãƒƒãƒï¼‰
        if job_ids:
            values = [(user_id, session_id, job_id) for job_id in job_ids]
            cur.executemany("""
                INSERT INTO user_filtered_jobs (user_id, session_id, job_id)
                VALUES (%s, %s, %s)
            """, values)
        
        conn.commit()
        cur.close()
        conn.close()
        
        print(f"âœ“ Saved {len(job_ids)} job IDs to database")
        
    except Exception as e:
        print(f"Error saving filtered job IDs: {e}")


def get_filtered_job_ids_from_db(user_id: int, session_id: str) -> List[str]:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœã‚’å–å¾—"""
    try:
        conn = get_db_conn()
        cur = conn.cursor()
        
        cur.execute("""
            SELECT job_id FROM user_filtered_jobs
            WHERE user_id = %s AND session_id = %s
            ORDER BY created_at
        """, (user_id, session_id))
        
        job_ids = [row[0] for row in cur.fetchall()]
        
        cur.close()
        conn.close()
        
        return job_ids
        
    except Exception as e:
        print(f"Error getting filtered job IDs: {e}")
        return []
    
def is_valid_answer_for_question(question_id: int, user_message: str) -> bool:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ãŒè³ªå•ã«å¯¾ã—ã¦å¦¥å½“ã‹ã©ã†ã‹ã‚’åˆ¤å®š
    
    Args:
        question_id: è³ªå•ID
        user_message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    
    Returns:
        å¦¥å½“ãªã‚‰Trueã€ä¸é©åˆ‡ãªã‚‰False
    """
    try:
        conn = get_db_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # è³ªå•ã‚’å–å¾—
        cur.execute("""
            SELECT question_key, question_text
            FROM dynamic_questions
            WHERE id = %s
        """, (question_id,))
        
        question = cur.fetchone()
        
        cur.close()
        conn.close()
        
        if not question:
            return True  # è³ªå•ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯é€šé
        
        # GPT-4ã§åˆ¤å®š
        prompt = f"""
ã‚ãªãŸã¯æ±‚äººãƒãƒƒãƒãƒ³ã‚°AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®è³ªå•ã«å¯¾ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ãŒã€è³ªå•ã«ç­”ãˆã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

ã€è³ªå•ã€‘
{question['question_text']}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã€‘
{user_message}

ã€åˆ¤å®šåŸºæº–ã€‘
- è³ªå•ã«å¯¾ã—ã¦ç›´æ¥ç­”ãˆã¦ã„ã‚‹å ´åˆ: valid
- è³ªå•ã¨ã¯é–¢ä¿‚ãªã„è©±é¡Œï¼ˆã€Œä»–ã«ã‚ªã‚¹ã‚¹ãƒ¡ã‚ã‚Šã¾ã™ã‹ï¼Ÿã€ã€Œæ±‚äººã‚’è¦‹ã›ã¦ã€ãªã©ï¼‰: invalid
- æ›–æ˜§ã ãŒè³ªå•ã«é–¢é€£ã—ã¦ã„ã‚‹å ´åˆ: valid

ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š
{{
  "is_valid": true ã¾ãŸã¯ false,
  "reason": "åˆ¤å®šç†ç”±ï¼ˆç°¡æ½”ã«ï¼‰"
}}
"""
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=150
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # JSONã‚’æŠ½å‡º
        import re
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if json_match:
            result_text = json_match.group(0)
        
        result = json.loads(result_text)
        
        is_valid = result.get('is_valid', True)
        reason = result.get('reason', '')
        
        print(f">>> Answer validation: {is_valid} - {reason}")
        
        return is_valid
        
    except Exception as e:
        print(f"Error validating answer: {e}")
        import traceback
        traceback.print_exc()
        return True  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯é€šéã•ã›ã‚‹
    
def save_user_response_with_normalization(user_id: int, question_id: int, response_text: str) -> bool:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã‚’æ­£è¦åŒ–ã—ã¦ä¿å­˜
    
    Args:
        user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        question_id: è³ªå•ID
        response_text: å›ç­”ãƒ†ã‚­ã‚¹ãƒˆ
    
    Returns:
        æˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    try:
        conn = get_db_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # è³ªå•ã®ã‚­ãƒ¼ã‚’å–å¾—
        cur.execute("""
            SELECT question_key
            FROM dynamic_questions
            WHERE id = %s
        """, (question_id,))
        
        question = cur.fetchone()
        
        if not question:
            print(f"âš  Question {question_id} not found")
            cur.close()
            conn.close()
            return False
        
        question_key = question['question_key']
        
        # GPT-4ã§æ­£è¦åŒ–ï¼ˆæ„å›³æŠ½å‡ºï¼‰
        normalized = normalize_response_with_gpt(question_key, response_text)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        cur.execute("""
            INSERT INTO user_question_responses (user_id, question_id, response_text, normalized_response)
            VALUES (%s, %s, %s, %s)
            ON CONFLICT (user_id, question_id) 
            DO UPDATE SET 
                response_text = EXCLUDED.response_text,
                normalized_response = EXCLUDED.normalized_response,
                created_at = NOW()
        """, (user_id, question_id, response_text, normalized))
        
        conn.commit()
        cur.close()
        conn.close()
        
        return True
        
    except Exception as e:
        print(f"Error saving user response: {e}")
        import traceback
        traceback.print_exc()
        return False


def normalize_response_with_gpt(question_key: str, response_text: str) -> str:
    """
    GPT-4ã§å›ç­”ã‚’æ­£è¦åŒ–
    
    Args:
        question_key: è³ªå•ã‚­ãƒ¼ï¼ˆremote, flex_time, ãªã©ï¼‰
        response_text: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ãƒ†ã‚­ã‚¹ãƒˆ
    
    Returns:
        æ­£è¦åŒ–ã•ã‚ŒãŸå›ç­”
    """
    try:
        # ç°¡å˜ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒã§æ­£è¦åŒ–
        text_lower = response_text.lower().strip()
        
        # ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        positive_keywords = [
            'ã¯ã„', 'yes', 'ã™ã‚‹', 'å¸Œæœ›', 'ã„ã„', 'è‰¯ã„', 'ã§ãã‚‹', 
            'å¯èƒ½', 'ã—ãŸã„', 'ã‚ã‚‹', 'ã‚ã‚Š', 'é­…åŠ›çš„', 'å¤§åˆ‡', 'å„ªå…ˆ',
            'å°‘ãªã‚', 'å°‘ãªã„', 'ãƒªãƒ¢ãƒ¼ãƒˆ', 'ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹', 'å¤§ä¼æ¥­', 'å¤§æ‰‹',
            'æ´»æ°—', 'ãƒãƒ£ãƒ¬ãƒ³ã‚¸', 'æˆé•·', 'ç ”ä¿®', 'æ˜‡é€²', 'å¤šã„', 'èˆˆå‘³'
        ]
        
        # ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        negative_keywords = [
            'ã„ã„ãˆ', 'no', 'ã—ãªã„', 'å¸Œæœ›ã—ãªã„', 'ä¸è¦', 'ãªãã¦ã‚‚',
            'å¤§ä¸ˆå¤«', 'è€ƒãˆãªã„', 'é‡è¦–ã—ãªã„', 'ã§ããªãã¦ã‚‚', 'ç‰¹ã«', 
            'ãªã„', 'ãªã„ã§ã™', 'èˆˆå‘³ãªã„', 'èˆˆå‘³ã¯ãªã„'
        ]
        
        is_positive = any(kw in text_lower for kw in positive_keywords)
        is_negative = any(kw in text_lower for kw in negative_keywords)
        
        # ãƒ†ã‚­ã‚¹ãƒˆè§£é‡ˆãŒå¿…è¦ãªé …ç›®
        text_keys = ['company_type', 'overtime', 'atmosphere', 'promotion']
        
        if question_key in text_keys:
            # ãƒ†ã‚­ã‚¹ãƒˆã®ã¾ã¾è¿”ã™
            return response_text
        else:
            # çœŸå½å€¤ã¨ã—ã¦æ­£è¦åŒ–
            if is_positive and not is_negative:
                return 'ã¯ã„'
            elif is_negative:
                return 'ã„ã„ãˆ'
            else:
                # ã©ã¡ã‚‰ã§ã‚‚ãªã„å ´åˆã¯ãã®ã¾ã¾
                return response_text
        
    except Exception as e:
        print(f"Error normalizing response: {e}")
        return response_text

@app.route("/api/chat", methods=["POST"])
def chat_api():
    """ãƒãƒ£ãƒƒãƒˆAPI - è‡ªç„¶ãªä¼šè©±å½¢å¼ã§è³ªå•ç”Ÿæˆï¼ˆç´¯ç©çµã‚Šè¾¼ã¿ç‰ˆ + å›ç­”æ¤œè¨¼ä»˜ãï¼‰"""
    if 'user_id' not in session:
        return jsonify({"error": "Unauthorized"}), 401

    user_id = session["user_id"]
    user_msg = request.json["message"]
    session_id = get_or_create_session_id()

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä¿å­˜
    ChatHistoryManager.save_message(user_id, 'user', user_msg, session_id=session_id)

    # â˜…â˜…â˜… æœ€å¾Œã®è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‹ãƒã‚§ãƒƒã‚¯ â˜…â˜…â˜…
    if 'last_question_key' in session:
        question_key = session['last_question_key']
        question_text = session.get('last_question_text', '')
        question_category = session.get('last_question_category', 'åƒãæ–¹ã®æŸ”è»Ÿæ€§')
        
        print(f">>> Saving response for question_key: {question_key}")
        
        # â˜…â˜…â˜… å‹•çš„è³ªå•ã®å›ç­”ã‚’ä¿å­˜ â˜…â˜…â˜…
        normalized = normalize_response_with_gpt(question_key, user_msg)
        success = dynamic_question_gen.save_question_and_response(
            user_id=user_id,
            question_key=question_key,
            question_text=question_text,
            category=question_category,
            response_text=user_msg,
            normalized_response=normalized
        )
        
        if success:
            print(f"âœ“ Dynamic question response saved successfully")
        else:
            print(f"âš  Failed to save dynamic question response")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å‰Šé™¤
        session.pop('last_question_key', None)
        session.pop('last_question_text', None)
        session.pop('last_question_category', None)
    else:
        print(f"âš  No last_question_key in session")

    # â˜…â˜…â˜… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å‰å›ã®çµæœIDãƒªã‚¹ãƒˆã‚’å–å¾— â˜…â˜…â˜…
    previous_job_ids = get_filtered_job_ids_from_db(user_id, session_id)
    
    if previous_job_ids:
        print(f">>> Using previous results from DB: {len(previous_job_ids)} jobs")
    else:
        print(f">>> No previous results, searching from scratch")

    # æ¨è–¦ã‚’å–å¾—ï¼ˆä¸Šé™ãªã—ï¼‰
    recommendations = HybridRecommender.get_hybrid_recommendations(
        user_id, 
        top_k=None,
        previous_job_ids=previous_job_ids
    )

    count = len(recommendations)
    print(f"\n>>> After filtering: {count} jobs remaining\n")

    # ä»Šå›ã®çµæœIDãƒªã‚¹ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    current_job_ids = [str(job['id']) for job in recommendations]
    save_filtered_job_ids_to_db(user_id, session_id, current_job_ids)

    if count == 0:
        reply_text = "è©²å½“ã™ã‚‹æ±‚äººã¯ 0 ä»¶ã§ã™ã€‚æ¡ä»¶ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚"
        ChatHistoryManager.save_message(user_id, 'bot', reply_text, session_id=session_id)
        return jsonify({"reply": reply_text})

    # â˜…â˜…â˜… 3ä»¶ä»¥ä¸‹ãªã‚‰æœ€çµ‚æ®µéšï¼šçµã‚Šè¾¼ã‚“ã æ±‚äºº + ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ¤œç´¢ + é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼å¿œå‹Ÿæ±‚äºº â˜…â˜…â˜…
    if count <= 3:
        print("\n=== Final Stage: Showing Filtered Jobs + Embedding Recommendations + Similar User Jobs ===")
        
        # â˜…â˜…â˜… ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¼šè©±å±¥æ­´ã‚’ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åŒ–ï¼ˆä¿å­˜ï¼‰ â˜…â˜…â˜…
        update_user_conversation_embedding(user_id)
        
        # çµã‚Šè¾¼ã‚“ã æ±‚äººã®IDã‚’è¨˜éŒ²
        displayed_ids = [str(job['id']) for job in recommendations]
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ¤œç´¢ã§è¿½åŠ ã®2ä»¶ã‚’å–å¾—ï¼ˆæ—¢ã«è¡¨ç¤ºã—ãŸæ±‚äººã‚’é™¤å¤–ï¼‰
        best_matches = find_best_matches_with_embeddings(
            user_id, 
            filtered_jobs=None,  # å…¨æ±‚äººã‹ã‚‰æ¤œç´¢
            top_k=2,
            exclude_ids=displayed_ids  # æ—¢ã«è¡¨ç¤ºã—ãŸæ±‚äººã‚’é™¤å¤–
        )
        
        # â˜…â˜…â˜… é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿œå‹Ÿæ¸ˆã¿æ±‚äººã‚’1ä»¶å–å¾— â˜…â˜…â˜…
        similar_user_job = find_similar_user_applied_job(user_id)
        
        # çµã‚Šè¾¼ã‚“ã æ±‚äºº + AIæ¨è–¦ + é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼æ±‚äººã‚’çµåˆ
        all_jobs = recommendations + best_matches
        if similar_user_job:
            all_jobs.append(similar_user_job)
        
        # GPT-4ã§èª¬æ˜æ–‡ã‚’ç”Ÿæˆ
        explanation = generate_final_recommendation_with_gpt(user_id, all_jobs)
        
        # çµã‚Šè¾¼ã‚“ã æ±‚äººã‚’æ•´å½¢
        filtered_job_texts = []
        for i, job in enumerate(recommendations, 1):
            detail = (
                f"ğŸ¯ çµã‚Šè¾¼ã¿å€™è£œ{i}: {job['company_name']} / {job['job_title']}\n"
                f"ğŸ“ {job['location_prefecture']}\n"
                f"ğŸ’° å¹´å: {job['salary_min']}ä¸‡ã€œ{job['salary_max']}ä¸‡"
            )
            filtered_job_texts.append(detail)
        
        # AIæ¨è–¦ã‚’æ•´å½¢
        additional_job_texts = []
        if best_matches and len(best_matches) > 0:
            for i, job in enumerate(best_matches, 1):
                detail = (
                    f"â­ AIãŠã™ã™ã‚{i}: {job['company_name']} / {job['job_title']}\n"
                    f"ğŸ“ {job['location_prefecture']}\n"
                    f"ğŸ’° å¹´å: {job['salary_min']}ä¸‡ã€œ{job['salary_max']}ä¸‡\n"
                    f"ğŸ¯ ãƒãƒƒãƒåº¦: {job['similarity']:.1%}"
                )
                additional_job_texts.append(detail)
        
        # â˜…â˜…â˜… é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿œå‹Ÿæ±‚äººã‚’æ•´å½¢ â˜…â˜…â˜…
        similar_user_job_text = None
        if similar_user_job:
            similar_text = generate_similar_user_recommendation_text(user_id, similar_user_job)
            similar_user_job_text = (
                f"{similar_text}\n\n"
                f"ğŸ’¼ {similar_user_job['company_name']} / {similar_user_job['job_title']}\n"
                f"ğŸ“ {similar_user_job['location_prefecture']}\n"
                f"ğŸ’° å¹´å: {similar_user_job['salary_min']}ä¸‡ã€œ{similar_user_job['salary_max']}ä¸‡\n"
                f"ğŸ‘¥ é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ {similar_user_job['apply_count']}äººãŒå¿œå‹Ÿ"
            )
        
        # æœ€çµ‚çš„ãªè¡¨ç¤º
        total_count = len(recommendations) + len(best_matches) + (1 if similar_user_job else 0)
        
        reply_text = f"{explanation}\n\n"
        reply_text += f"ã€çµã‚Šè¾¼ã‚“ã å€™è£œï¼ˆ{len(recommendations)}ä»¶ï¼‰ã€‘\n\n"
        reply_text += "\n\n".join(filtered_job_texts)
        
        if additional_job_texts:
            reply_text += f"\n\nã€AIãŒé¸ã‚“ã è¿½åŠ ã®ãŠã™ã™ã‚ï¼ˆ{len(best_matches)}ä»¶ï¼‰ã€‘\n\n"
            reply_text += "\n\n".join(additional_job_texts)
        
        if similar_user_job_text:
            reply_text += f"\n\nã€é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¿œå‹Ÿã—ãŸæ±‚äººã€‘\n\n"
            reply_text += similar_user_job_text
        
        reply_text += f"\n\nâœ¨ åˆè¨ˆ {total_count} ä»¶ã®æ±‚äººã‚’ã”ç´¹ä»‹ã—ã¾ã—ãŸã€‚"
        
        ChatHistoryManager.save_message(user_id, 'bot', reply_text, session_id=session_id)
        return jsonify({"reply": reply_text})

    # â˜…â˜…â˜… 4ä»¶ä»¥ä¸Šãªã‚‰å®Œå…¨å‹•çš„ã«è³ªå•ã‚’ç”Ÿæˆï¼ˆæ±‚äººãƒªã‚¹ãƒˆã¯è¡¨ç¤ºã—ãªã„ï¼‰ â˜…â˜…â˜…
    next_question = dynamic_question_gen.generate_next_question(user_id, recommendations, user_msg)

    if next_question:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è³ªå•æƒ…å ±ã‚’ä¿å­˜
        session['last_question_key'] = next_question['question_key']
        session['last_question_text'] = next_question['question_text']
        session['last_question_category'] = next_question.get('category', 'åƒãæ–¹ã®æŸ”è»Ÿæ€§')
        print(f">>> Stored question_key in session: {next_question['question_key']}")
        
        # â˜…â˜…â˜… æ±‚äººãƒªã‚¹ãƒˆã¯è¡¨ç¤ºã›ãšã€ä»¶æ•°ã¨è³ªå•ã®ã¿ â˜…â˜…â˜…
        reply_text = f"è©²å½“æ±‚äººæ•°ã¯ {count} ä»¶ã§ã™ã€‚\n\n{next_question['question_text']}"
    else:
        # â˜…â˜…â˜… è³ªå•ãŒãªã„å ´åˆã‚‚ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ¤œç´¢ + é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼æ±‚äººã‚’å«ã‚ã¦è¡¨ç¤º â˜…â˜…â˜…
        print("\n=== No more questions, switching to Embedding Search ===")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¼šè©±å±¥æ­´ã‚’ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åŒ–
        update_user_conversation_embedding(user_id)
        
        # çµã‚Šè¾¼ã‚“ã æ±‚äººï¼ˆæœ€å¤§3ä»¶ï¼‰
        displayed_ids = [str(job['id']) for job in recommendations[:3]]
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ¤œç´¢ã§è¿½åŠ ã®2ä»¶ã‚’å–å¾—
        best_matches = find_best_matches_with_embeddings(
            user_id, 
            filtered_jobs=None,
            top_k=2,
            exclude_ids=displayed_ids
        )
        
        # é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿œå‹Ÿæ¸ˆã¿æ±‚äººã‚’1ä»¶å–å¾—
        similar_user_job = find_similar_user_applied_job(user_id)
        
        # çµåˆ
        all_jobs = recommendations[:3] + best_matches
        if similar_user_job:
            all_jobs.append(similar_user_job)
        
        # GPT-4ã§èª¬æ˜æ–‡ã‚’ç”Ÿæˆ
        explanation = generate_final_recommendation_with_gpt(user_id, all_jobs)
        
        # æ•´å½¢
        filtered_job_texts = []
        for i, job in enumerate(recommendations[:3], 1):
            detail = (
                f"ğŸ¯ çµã‚Šè¾¼ã¿å€™è£œ{i}: {job['company_name']} / {job['job_title']}\n"
                f"ğŸ“ {job['location_prefecture']}\n"
                f"ğŸ’° å¹´å: {job['salary_min']}ä¸‡ã€œ{job['salary_max']}ä¸‡"
            )
            filtered_job_texts.append(detail)
        
        additional_job_texts = []
        if best_matches and len(best_matches) > 0:
            for i, job in enumerate(best_matches, 1):
                detail = (
                    f"â­ AIãŠã™ã™ã‚{i}: {job['company_name']} / {job['job_title']}\n"
                    f"ğŸ“ {job['location_prefecture']}\n"
                    f"ğŸ’° å¹´å: {job['salary_min']}ä¸‡ã€œ{job['salary_max']}ä¸‡\n"
                    f"ğŸ¯ ãƒãƒƒãƒåº¦: {job['similarity']:.1%}"
                )
                additional_job_texts.append(detail)
        
        similar_user_job_text = None
        if similar_user_job:
            similar_text = generate_similar_user_recommendation_text(user_id, similar_user_job)
            similar_user_job_text = (
                f"{similar_text}\n\n"
                f"ğŸ’¼ {similar_user_job['company_name']} / {similar_user_job['job_title']}\n"
                f"ğŸ“ {similar_user_job['location_prefecture']}\n"
                f"ğŸ’° å¹´å: {similar_user_job['salary_min']}ä¸‡ã€œ{similar_user_job['salary_max']}ä¸‡\n"
                f"ğŸ‘¥ é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ {similar_user_job['apply_count']}äººãŒå¿œå‹Ÿ"
            )
        
        total_count = min(len(recommendations), 3) + len(best_matches) + (1 if similar_user_job else 0)
        
        reply_text = f"{explanation}\n\n"
        reply_text += f"ã€çµã‚Šè¾¼ã‚“ã å€™è£œï¼ˆ{min(len(recommendations), 3)}ä»¶ï¼‰ã€‘\n\n"
        reply_text += "\n\n".join(filtered_job_texts)
        
        if additional_job_texts:
            reply_text += f"\n\nã€AIãŒé¸ã‚“ã è¿½åŠ ã®ãŠã™ã™ã‚ï¼ˆ{len(best_matches)}ä»¶ï¼‰ã€‘\n\n"
            reply_text += "\n\n".join(additional_job_texts)
        
        if similar_user_job_text:
            reply_text += f"\n\nã€é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¿œå‹Ÿã—ãŸæ±‚äººã€‘\n\n"
            reply_text += similar_user_job_text
        
        reply_text += f"\n\nâœ¨ åˆè¨ˆ {total_count} ä»¶ã®æ±‚äººã‚’ã”ç´¹ä»‹ã—ã¾ã—ãŸã€‚"

    ChatHistoryManager.save_message(user_id, 'bot', reply_text, session_id=session_id)
    return jsonify({"reply": reply_text})


def generate_final_recommendation_with_gpt(user_id: int, matched_jobs: List[Dict]) -> str:
    """
    GPT-4ã§æœ€çµ‚ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ–‡ã‚’ç”Ÿæˆ
    
    Args:
        user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        matched_jobs: ãƒãƒƒãƒã—ãŸæ±‚äººãƒªã‚¹ãƒˆï¼ˆçµã‚Šè¾¼ã¿+AIæ¨è–¦ã®å…¨ã¦ï¼‰
    
    Returns:
        èª¬æ˜æ–‡
    """
    try:
        conn = get_db_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”å±¥æ­´ã‚’å–å¾—
        cur.execute("""
            SELECT dq.question_text, uqr.response_text
            FROM user_question_responses uqr
            JOIN dynamic_questions dq ON uqr.question_id = dq.id
            WHERE uqr.user_id = %s
            ORDER BY uqr.created_at
        """, (user_id,))
        
        responses = cur.fetchall()
        
        cur.close()
        conn.close()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¡ä»¶ã‚’æ•´ç†
        conditions_text = "\n".join([
            f"- {resp['question_text']}: {resp['response_text']}"
            for resp in responses
        ])
        
        # æ±‚äººæƒ…å ±ã‚’æ•´ç†
        jobs_text = ""
        for i, job in enumerate(matched_jobs, 1):
            jobs_text += f"\n{i}. {job['company_name']} / {job['job_title']}\n"
            jobs_text += f"   å¹´å: {job['salary_min']}ä¸‡ã€œ{job['salary_max']}ä¸‡\n"
            if 'similarity' in job:
                jobs_text += f"   ãƒãƒƒãƒåº¦: {job['similarity']:.1%}\n"
        
        prompt = f"""
ã‚ãªãŸã¯æ±‚äººãƒãƒƒãƒãƒ³ã‚°AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¸Œæœ›æ¡ä»¶ã«åŸºã¥ã„ã¦ã€æœ€ã‚‚ãƒãƒƒãƒã™ã‚‹æ±‚äººã‚’å³é¸ã—ã¾ã—ãŸã€‚

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¸Œæœ›æ¡ä»¶ã€‘
{conditions_text}

ã€å³é¸ã—ãŸæ±‚äººã€‘
{jobs_text}

ã€ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯ã€‘
ä¸Šè¨˜ã®æ±‚äººãŒãªãœãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãƒãƒƒãƒã™ã‚‹ã®ã‹ã€æ¸©ã‹ã¿ã®ã‚ã‚‹æ–‡ç« ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
1. å°å…¥æ–‡ï¼ˆã€Œã‚ãªãŸã®å¸Œæœ›ã«æœ€ã‚‚ãƒãƒƒãƒã™ã‚‹æ±‚äººã‚’å³é¸ã—ã¾ã—ãŸã€ãªã©ï¼‰
2. æ±‚äººã®é­…åŠ›ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¡ä»¶ã¨ã®ä¸€è‡´ç‚¹ï¼‰
3. å‰å‘ããªç· ã‚ããã‚Šï¼ˆå¿…ãšå®Œçµã•ã›ã‚‹ã“ã¨ï¼‰

è‡ªç„¶ã§è¦ªã—ã¿ã‚„ã™ã„ãƒˆãƒ¼ãƒ³ã§ã€3ã€œ4æ–‡ç¨‹åº¦ã§æ›¸ã„ã¦ãã ã•ã„ã€‚
**é‡è¦**: æ–‡ç« ã‚’é€”ä¸­ã§çµ‚ã‚ã‚‰ã›ãšã€å¿…ãšå®Œçµã•ã›ã¦ãã ã•ã„ã€‚
"""

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=500
        )

        explanation = response.choices[0].message.content.strip()
        return explanation

    except Exception as e:
        print(f"Error generating explanation: {e}")
        import traceback
        traceback.print_exc()
        return f"ã‚ãªãŸã®å¸Œæœ›æ¡ä»¶ã«åˆã£ãŸæ±‚äººã‚’ {len(top_jobs)} ä»¶è¦‹ã¤ã‘ã¾ã—ãŸï¼"
    
def find_similar_users_conversation_history(user_id: int, limit: int = 5) -> List[Dict]:
    """
    é¡ä¼¼æ¡ä»¶ã‚’æŒã¤éå»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—
    
    Args:
        user_id: ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        limit: å–å¾—ã™ã‚‹é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°
    
    Returns:
        é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¼šè©±å±¥æ­´ãƒªã‚¹ãƒˆ
    """
    try:
        conn = get_db_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        cur.execute("""
            SELECT job_title, location_prefecture
            FROM user_profile
            WHERE user_id = %s
        """, (user_id,))
        
        current_profile = cur.fetchone()
        
        if not current_profile:
            cur.close()
            conn.close()
            return []
        
        # â˜…â˜…â˜… SQLä¿®æ­£ï¼šSELECT DISTINCTã¨ORDER BYã®å•é¡Œã‚’è§£æ±º â˜…â˜…â˜…
        cur.execute("""
            WITH successful_users AS (
                SELECT 
                    up.user_id,
                    COUNT(DISTINCT ui.job_id) as interaction_count
                FROM user_profile up
                JOIN user_interactions ui ON up.user_id = ui.user_id
                WHERE up.job_title ILIKE %s
                  AND up.location_prefecture ILIKE %s
                  AND up.user_id != %s
                  AND ui.interaction_type IN ('apply', 'favorite', 'click')
                GROUP BY up.user_id
                HAVING COUNT(DISTINCT ui.job_id) >= 1
                ORDER BY interaction_count DESC
                LIMIT %s
            )
            SELECT 
                su.user_id,
                up.job_title,
                up.location_prefecture,
                COUNT(DISTINCT uqr.id) as total_responses
            FROM successful_users su
            JOIN user_profile up ON su.user_id = up.user_id
            LEFT JOIN user_question_responses uqr ON su.user_id = uqr.user_id
            GROUP BY su.user_id, up.job_title, up.location_prefecture
            ORDER BY total_responses DESC
        """, (
            f"%{current_profile['job_title']}%",
            f"%{current_profile['location_prefecture']}%",
            user_id,
            limit
        ))
        
        similar_users = cur.fetchall()
        
        if not similar_users:
            print("âš  No similar users found")
            cur.close()
            conn.close()
            return []
        
        print(f"âœ“ Found {len(similar_users)} similar users")
        
        # å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—
        conversation_histories = []
        
        for user in similar_users:
            similar_user_id = user['user_id']
            
            # è³ªå•ã¨å›ç­”ã‚’å–å¾—
            cur.execute("""
                SELECT 
                    dq.question_key,
                    dq.question_text,
                    uqr.response_text,
                    uqr.normalized_response,
                    uqr.created_at
                FROM user_question_responses uqr
                JOIN dynamic_questions dq ON uqr.question_id = dq.id
                WHERE uqr.user_id = %s
                ORDER BY uqr.created_at
            """, (similar_user_id,))
            
            responses = cur.fetchall()
            
            # ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ€çµ‚çš„ã«è¦‹ãŸæ±‚äººã‚’å–å¾—
            cur.execute("""
                SELECT COUNT(DISTINCT job_id) as viewed_jobs
                FROM user_interactions
                WHERE user_id = %s
                  AND interaction_type IN ('apply', 'favorite', 'click')
            """, (similar_user_id,))
            
            interaction_count = cur.fetchone()['viewed_jobs']
            
            conversation_histories.append({
                'user_id': similar_user_id,
                'job_title': user['job_title'],
                'location': user['location_prefecture'],
                'responses': [dict(r) for r in responses],
                'total_interactions': interaction_count
            })
        
        cur.close()
        conn.close()
        
        return conversation_histories
        
    except Exception as e:
        print(f"Error finding similar users: {e}")
        import traceback
        traceback.print_exc()
        return []


def analyze_successful_question_patterns(conversation_histories: List[Dict]) -> str:
    """
    æˆåŠŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã—ã¦ãƒ†ã‚­ã‚¹ãƒˆåŒ–
    
    Args:
        conversation_histories: é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¼šè©±å±¥æ­´
    
    Returns:
        åˆ†æçµæœã®ãƒ†ã‚­ã‚¹ãƒˆ
    """
    if not conversation_histories:
        return "å‚è€ƒãƒ‡ãƒ¼ã‚¿ãªã—"
    
    # è³ªå•ã‚­ãƒ¼ã®å‡ºç¾é »åº¦ã‚’é›†è¨ˆ
    question_freq = {}
    question_examples = {}
    
    for history in conversation_histories:
        for response in history['responses']:
            q_key = response['question_key']
            q_text = response['question_text']
            r_text = response['response_text']
            
            if q_key not in question_freq:
                question_freq[q_key] = 0
                question_examples[q_key] = []
            
            question_freq[q_key] += 1
            question_examples[q_key].append({
                'question': q_text,
                'answer': r_text
            })
    
    # é »åº¦ã®é«˜ã„è³ªå•é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_questions = sorted(question_freq.items(), key=lambda x: x[1], reverse=True)
    
    # ãƒ†ã‚­ã‚¹ãƒˆåŒ–
    analysis_text = "ã€é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç­”ãˆãŸè³ªå•ãƒˆãƒƒãƒ—5ã€‘\n"
    
    for i, (q_key, freq) in enumerate(sorted_questions[:5], 1):
        examples = question_examples[q_key][:2]  # æœ€å¤§2ä¾‹
        analysis_text += f"\n{i}. {q_key} (å›ç­”ç‡: {freq}/{len(conversation_histories)}äºº)\n"
        
        for example in examples:
            analysis_text += f"   Q: {example['question']}\n"
            analysis_text += f"   A: {example['answer']}\n"
    
    return analysis_text
    
def generate_conversational_question(user_id: int, recommendations: List[Dict], user_last_message: str) -> Optional[Dict[str, Any]]:
    """GPT-4ã§è‡ªç„¶ãªä¼šè©±å½¢å¼ã®è³ªå•ã‚’ç”Ÿæˆï¼ˆé¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼å‚ç…§ç‰ˆï¼‰"""
    try:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”å±¥æ­´ã‚’å–å¾—
        conn = get_db_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # æ—¢ã«å›ç­”æ¸ˆã¿ã®è³ªå•ã¨å›ç­”å†…å®¹ã‚’å–å¾—
        cur.execute("""
            SELECT dq.question_key, dq.question_text, uqr.response_text
            FROM user_question_responses uqr
            JOIN dynamic_questions dq ON uqr.question_id = dq.id
            WHERE uqr.user_id = %s
            ORDER BY uqr.created_at
        """, (user_id,))
        
        answered_questions = cur.fetchall()
        answered_keys = set([row['question_key'] for row in answered_questions])
        print(f"Already answered: {answered_keys}")

        # æœªå›ç­”ã®è³ªå•ã®ã¿å–å¾—
        if answered_keys:
            placeholders = ','.join(['%s'] * len(answered_keys))
            cur.execute(f"""
                SELECT id, question_key, question_text, category 
                FROM dynamic_questions
                WHERE question_key NOT IN ({placeholders})
                ORDER BY id
                LIMIT 20
            """, tuple(answered_keys))
        else:
            cur.execute("""
                SELECT id, question_key, question_text, category 
                FROM dynamic_questions
                ORDER BY id
                LIMIT 20
            """)

        available_questions = cur.fetchall()
        
        if not available_questions:
            print("âš  No more questions available")
            cur.close()
            conn.close()
            return None

        print(f"Available questions: {len(available_questions)}")
        
        # æ±‚äººã®å·®åˆ†ã‚’åˆ†æ
        cur.execute("""
            SELECT ja.company_culture, ja.work_flexibility, ja.career_path
            FROM job_attributes ja
            WHERE ja.job_id::text IN %s
            LIMIT 20
        """, (tuple([str(job['id']) for job in recommendations[:20]]),))
        
        job_attributes = cur.fetchall()
        
        cur.close()
        conn.close()
        
        # â˜…â˜…â˜… é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¼šè©±å±¥æ­´ã‚’å–å¾— â˜…â˜…â˜…
        print("\n=== Fetching Similar Users' Conversation History ===")
        similar_users_history = find_similar_users_conversation_history(user_id, limit=5)
        
        # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        success_patterns = analyze_successful_question_patterns(similar_users_history)
        print(f"\n{success_patterns}")
        
        # å›ç­”æ¸ˆã¿ã®è³ªå•ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
        answered_text = "\n".join([
            f"- {q['question_text']}: {q['response_text']}"
            for q in answered_questions
        ]) if answered_questions else "ã¾ã è³ªå•ã«ç­”ãˆã¦ã„ã¾ã›ã‚“"
        
        # æ±‚äººã®ç‰¹å¾´ã‚’åˆ†æ
        remote_count = sum(1 for attr in job_attributes if attr.get('work_flexibility', {}).get('remote') == True)
        flex_count = sum(1 for attr in job_attributes if attr.get('work_flexibility', {}).get('flex_time') == True)
        large_company_count = sum(1 for attr in job_attributes if attr.get('company_culture', {}).get('size') == 'large')
        training_count = sum(1 for attr in job_attributes if attr.get('career_path', {}).get('training') == True)
        
        # â˜…â˜…â˜… é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æƒ…å ±ã‚’å«ã‚ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ â˜…â˜…â˜…
        prompt = f"""
ã‚ãªãŸã¯æ±‚äººãƒãƒƒãƒãƒ³ã‚°AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨è‡ªç„¶ãªä¼šè©±ã‚’ã—ãªãŒã‚‰ã€æœ€é©ãªæ±‚äººã‚’çµã‚Šè¾¼ã‚“ã§ã„ã¾ã™ã€‚

ã€ç¾åœ¨ã®çŠ¶æ³ã€‘
- è©²å½“æ±‚äººæ•°: {len(recommendations)}ä»¶
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: "{user_last_message}"

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ—¢ã«å›ç­”ã—ãŸè³ªå•ã€‘
{answered_text}

ã€æ±‚äººã®ç‰¹å¾´åˆ†æã€‘
- ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯å¯èƒ½: {remote_count}/{len(job_attributes)}ä»¶
- ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ åˆ¶: {flex_count}/{len(job_attributes)}ä»¶
- å¤§ä¼æ¥­: {large_company_count}/{len(job_attributes)}ä»¶
- ç ”ä¿®åˆ¶åº¦å……å®Ÿ: {training_count}/{len(job_attributes)}ä»¶

ã€â˜…å‚è€ƒâ˜… åŒã˜æ¡ä»¶ã§æ±‚äººã‚’æ¢ã—ãŸéå»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å‚¾å‘ã€‘
{success_patterns}

ä¸Šè¨˜ã®éå»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€ã“ã‚Œã‚‰ã®è³ªå•ã«ç­”ãˆã‚‹ã“ã¨ã§ã€æœ€çµ‚çš„ã«å¸Œæœ›ã®æ±‚äººã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚
ã“ã®æƒ…å ±ã‚’å‚è€ƒã«ã€ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚‚åŠ¹æœçš„ãªè³ªå•ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚

ã€ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯ã€‘
ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã€æ¬¡ã«èãã¹ãè³ªå•ã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š

1. **æ—¢ã«èã„ãŸè³ªå•ã¯çµ¶å¯¾ã«èã‹ãªã„**
2. **éå»ã®æˆåŠŸãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç­”ãˆãŸè³ªå•ã‚’å„ªå…ˆçš„ã«å‚è€ƒã«ã™ã‚‹**
3. **è‡ªç„¶ãªä¼šè©±å½¢å¼ã§è³ªå•ã™ã‚‹**ï¼ˆã€Œã€œã«ã¤ã„ã¦ã¯ã©ã†ã§ã™ã‹ï¼Ÿã€ã€Œã€œã¯æ°—ã«ãªã‚Šã¾ã™ã‹ï¼Ÿã€ãªã©ï¼‰
4. **æ±‚äººã®å·®åˆ†ãŒã‚ã‚‹é …ç›®ã«ã¤ã„ã¦èã**ï¼ˆä¾‹: ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚ã‚Šãªã—ãŒæ··åœ¨ã—ã¦ã„ã‚‹å ´åˆï¼‰
5. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¸ã¾ãˆã¦ã€è‡ªç„¶ãªæµã‚Œã§è³ªå•ã™ã‚‹**
6. **ä¸€å•ä¸€ç­”ã§ã¯ãªãã€ä¼šè©±çš„ã«**

ã€åˆ©ç”¨å¯èƒ½ãªè³ªå•ã‚­ãƒ¼ã€‘
ä»¥ä¸‹ã‹ã‚‰é¸ã‚“ã§ãã ã•ã„ï¼š
- remote: ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯
- flex_time: ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ åˆ¶åº¦
- side_job: å‰¯æ¥­
- overtime: æ®‹æ¥­æ™‚é–“
- company_type: ä¼æ¥­è¦æ¨¡
- atmosphere: è·å ´ã®é›°å›²æ°—
- growth: ã‚­ãƒ£ãƒªã‚¢æˆé•·æ©Ÿä¼š
- training: ç ”ä¿®åˆ¶åº¦
- promotion: æ˜‡é€²ã‚¹ãƒ”ãƒ¼ãƒ‰

ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚ã‚‚ã—é©åˆ‡ãªè³ªå•ãŒãªã„ã€ã¾ãŸã¯å…¨ã¦ã®é‡è¦ãªè³ªå•ã‚’èãçµ‚ãˆãŸå ´åˆã¯ã€question_key ã‚’ null ã«ã—ã¦ãã ã•ã„ã€‚

{{
  "question_key": "remote" ã¾ãŸã¯ null,
  "question_text": "è‡ªç„¶ãªè³ªå•æ–‡"
}}

è³ªå•æ–‡ã®ã¿è¿”ã—ã¦ãã ã•ã„ï¼ˆèª¬æ˜ä¸è¦ï¼‰ã€‚
"""

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=200
        )

        result_text = response.choices[0].message.content.strip()
        
        # JSONã‚’æŠ½å‡º
        import re
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if json_match:
            result_text = json_match.group(0)
        
        result = json.loads(result_text)
        
        # question_keyãŒnullãªã‚‰è³ªå•çµ‚äº†
        if not result.get('question_key'):
            return None
        
        # æ—¢ã«å›ç­”æ¸ˆã¿ã®ã‚­ãƒ¼ãªã‚‰åˆ¥ã®è³ªå•ã‚’é¸ã¶
        if result.get('question_key') in answered_keys:
            print(f"âš  Question key '{result.get('question_key')}' already answered, skipping")
            return None
        
        # å¯¾å¿œã™ã‚‹è³ªå•IDã‚’å–å¾—
        conn = get_db_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute("""
            SELECT id FROM dynamic_questions
            WHERE question_key = %s
        """, (result['question_key'],))
        
        question_row = cur.fetchone()
        cur.close()
        conn.close()
        
        if question_row:
            return {
                'question_id': question_row['id'],
                'question_text': result['question_text']
            }
        else:
            print(f"âš  Question key '{result.get('question_key')}' not found in database")
            return {
                'question_text': result['question_text']
            }

    except Exception as e:
        print(f"Error generating conversational question: {e}")
        import traceback
        traceback.print_exc()
        return None

# --- ãŠæ°—ã«å…¥ã‚ŠAPI ---
@app.route("/api/favorite", methods=["POST"])
def add_favorite():
    """æ±‚äººã‚’ãŠæ°—ã«å…¥ã‚Šã«è¿½åŠ """
    if 'user_id' not in session:
        return jsonify({"error": "Unauthorized"}), 401

    user_id = session["user_id"]
    job_id = request.json["job_id"]

    success = UserInteractionTracker.add_favorite(user_id, job_id)

    if success:
        return jsonify({"status": "success", "message": "ãŠæ°—ã«å…¥ã‚Šã«è¿½åŠ ã—ã¾ã—ãŸ"})
    else:
        return jsonify({"status": "error", "message": "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"}), 500


@app.route("/api/favorite", methods=["DELETE"])
def remove_favorite():
    """ãŠæ°—ã«å…¥ã‚Šã‹ã‚‰å‰Šé™¤"""
    if 'user_id' not in session:
        return jsonify({"error": "Unauthorized"}), 401

    user_id = session["user_id"]
    job_id = request.json["job_id"]

    success = UserInteractionTracker.remove_favorite(user_id, job_id)

    if success:
        return jsonify({"status": "success", "message": "ãŠæ°—ã«å…¥ã‚Šã‹ã‚‰å‰Šé™¤ã—ã¾ã—ãŸ"})
    else:
        return jsonify({"status": "error", "message": "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"}), 500


@app.route("/api/favorites", methods=["GET"])
def get_favorites():
    """ãŠæ°—ã«å…¥ã‚Šä¸€è¦§ã‚’å–å¾—"""
    if 'user_id' not in session:
        return jsonify({"error": "Unauthorized"}), 401

    user_id = session["user_id"]
    favorites = UserInteractionTracker.get_user_favorites(user_id)

    return jsonify({"favorites": favorites})


# --- å¿œå‹ŸAPI ---
@app.route("/api/apply", methods=["POST"])
def apply():
    """æ±‚äººã«å¿œå‹Ÿ"""
    if 'user_id' not in session:
        return jsonify({"error": "Unauthorized"}), 401

    user_id = session["user_id"]
    job_id = request.json["job_id"]

    success = UserInteractionTracker.record_apply(user_id, job_id)

    if success:
        # å¿œå‹ŸãŒæˆåŠŸã—ãŸã‚‰ã€æœ€å¾Œã«å›ç­”ã—ãŸè³ªå•ã‚’åŠ¹æœçš„ã¨ãƒãƒ¼ã‚¯
        if 'last_question_id' in session:
            QuestionResponseManager.mark_question_as_effective(session['last_question_id'])

        return jsonify({"status": "success", "message": "å¿œå‹Ÿã‚’è¨˜éŒ²ã—ã¾ã—ãŸ"})
    else:
        return jsonify({"status": "error", "message": "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"}), 500


# --- ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«è¡¨ç¤º ---
@app.route("/profile")
def profile():
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«è¡¨ç¤º"""
    if 'user_id' not in session:
        return redirect(url_for("login"))

    user_id = session["user_id"]

    conn = get_db_conn()
    cur = conn.cursor(cursor_factory=RealDictCursor)

    cur.execute("""
        SELECT pd.user_name, pd.email, pd.birth_day, pd.phone_number, pd.address,
               up.job_title, up.location_prefecture, up.salary_min
        FROM personal_date pd
        INNER JOIN user_profile up ON pd.user_id = up.user_id
        WHERE pd.user_id = %s
    """, (user_id,))

    user_data = cur.fetchone()
    cur.close()
    conn.close()

    return render_template("profile.html", user=dict(user_data) if user_data else {})

def update_user_conversation_embedding(user_id: int):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¼šè©±å±¥æ­´ã‚’ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åŒ–ã—ã¦DBã«ä¿å­˜
    
    Args:
        user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
    """
    try:
        conn = get_db_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        cur.execute("""
            SELECT job_title, location_prefecture, salary_min
            FROM user_profile
            WHERE user_id = %s
        """, (user_id,))
        
        profile = cur.fetchone()
        
        if not profile:
            cur.close()
            conn.close()
            return
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•å›ç­”ã‚’å–å¾—
        cur.execute("""
            SELECT dq.question_text, uqr.response_text
            FROM user_question_responses uqr
            JOIN dynamic_questions dq ON uqr.question_id = dq.id
            WHERE uqr.user_id = %s
            ORDER BY uqr.created_at
        """, (user_id,))
        
        responses = cur.fetchall()
        
        # ä¼šè©±å±¥æ­´ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
        conversation_text = f"""
è·ç¨®: {profile['job_title']}
å‹¤å‹™åœ°: {profile['location_prefecture']}
å¸Œæœ›å¹´å: {profile['salary_min']}ä¸‡å††ä»¥ä¸Š

ã€å¸Œæœ›æ¡ä»¶ã€‘
"""
        
        for resp in responses:
            conversation_text += f"- {resp['question_text']}: {resp['response_text']}\n"
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åŒ–
        embedding = generate_embedding(conversation_text)
        
        if embedding is None:
            print("âš  Failed to generate embedding")
            cur.close()
            conn.close()
            return
        
        # JSONå½¢å¼ã§ä¿å­˜
        embedding_json = json.dumps(embedding)
        
        # DBã«ä¿å­˜
        cur.execute("""
            INSERT INTO user_conversation_embeddings (user_id, embedding_vector, conversation_summary, updated_at)
            VALUES (%s, %s, %s, NOW())
            ON CONFLICT (user_id) 
            DO UPDATE SET 
                embedding_vector = EXCLUDED.embedding_vector,
                conversation_summary = EXCLUDED.conversation_summary,
                updated_at = NOW()
        """, (user_id, embedding_json, conversation_text[:500]))
        
        conn.commit()
        cur.close()
        conn.close()
        
        print(f"âœ“ Updated conversation embedding for user {user_id}")
        
    except Exception as e:
        print(f"Error updating conversation embedding: {e}")
        import traceback
        traceback.print_exc()


def find_similar_user_applied_job(user_id: int) -> Optional[Dict[str, Any]]:
    """
    ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã§é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ¤œç´¢ã—ã€ãã®äººãŒå¿œå‹Ÿã—ãŸæ±‚äººã‚’1ä»¶è¿”ã™
    
    Args:
        user_id: ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
    
    Returns:
        ãŠã™ã™ã‚ã®æ±‚äººæƒ…å ±ï¼ˆ1ä»¶ï¼‰
    """
    try:
        conn = get_db_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’å–å¾—
        cur.execute("""
            SELECT embedding_vector
            FROM user_conversation_embeddings
            WHERE user_id = %s
        """, (user_id,))
        
        current_user_emb = cur.fetchone()
        
        if not current_user_emb:
            print("âš  No embedding found for current user")
            cur.close()
            conn.close()
            return None
        
        current_embedding = json.loads(current_user_emb['embedding_vector'])
        
        # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’å–å¾—
        cur.execute("""
            SELECT user_id, embedding_vector
            FROM user_conversation_embeddings
            WHERE user_id != %s
        """, (user_id,))
        
        all_users = cur.fetchall()
        
        if not all_users:
            print("âš  No other users with embeddings found")
            cur.close()
            conn.close()
            return None
        
        # é¡ä¼¼åº¦ã‚’è¨ˆç®—
        similarities = []
        for user in all_users:
            other_embedding = json.loads(user['embedding_vector'])
            
            similarity = cosine_similarity(
                [current_embedding],
                [other_embedding]
            )[0][0]
            
            similarities.append({
                'user_id': user['user_id'],
                'similarity': float(similarity)
            })
        
        # é¡ä¼¼åº¦ã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        
        print(f"\n=== Top 5 Similar Users by Embedding ===")
        for i, sim in enumerate(similarities[:5], 1):
            print(f"{i}. User {sim['user_id']} - Similarity: {sim['similarity']:.4f}")
        
        # ä¸Šä½5äººã®é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰å¿œå‹Ÿæ¸ˆã¿æ±‚äººã‚’å–å¾—
        similar_user_ids = [s['user_id'] for s in similarities[:5]]
        
        # â˜…â˜…â˜… ãƒ‡ãƒãƒƒã‚°ï¼šå„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿œå‹Ÿä»¶æ•°ã‚’ç¢ºèª â˜…â˜…â˜…
        print("\n=== Similar Users' Apply Data ===")
        for uid in similar_user_ids:
            cur.execute("""
                SELECT COUNT(*) as count
                FROM user_interactions
                WHERE user_id = %s AND interaction_type = 'apply'
            """, (uid,))
            count = cur.fetchone()['count']
            print(f"  User {uid}: {count} applies")
        
        # â˜…â˜…â˜… ãƒ‡ãƒãƒƒã‚°ï¼šç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ—¢ã«è¦‹ãŸæ±‚äººæ•°ã‚’ç¢ºèª â˜…â˜…â˜…
        cur.execute("""
            SELECT COUNT(DISTINCT job_id) as count
            FROM user_interactions
            WHERE user_id = %s
        """, (user_id,))
        excluded_count = cur.fetchone()['count']
        print(f"\n=== Current User's Interactions ===")
        print(f"  User {user_id} has interacted with {excluded_count} jobs (will be excluded)")
        
        # â˜…â˜…â˜… ãƒ‡ãƒãƒƒã‚°ï¼šé™¤å¤–å‰ã®å¿œå‹Ÿæ±‚äººæ•°ã‚’ç¢ºèª â˜…â˜…â˜…
        cur.execute("""
            SELECT COUNT(*) as count
            FROM user_interactions ui
            WHERE ui.user_id = ANY(%s)
              AND ui.interaction_type = 'apply'
        """, (similar_user_ids,))
        total_applies = cur.fetchone()['count']
        print(f"\n=== Available Jobs ===")
        print(f"  Total applies from similar users: {total_applies}")
        
        # â˜…â˜…â˜… ãƒ‡ãƒãƒƒã‚°ï¼šé™¤å¤–å¾Œã®å¿œå‹Ÿæ±‚äººæ•°ã‚’ç¢ºèª â˜…â˜…â˜…
        cur.execute("""
            SELECT COUNT(DISTINCT ui.job_id) as count
            FROM user_interactions ui
            WHERE ui.user_id = ANY(%s)
              AND ui.interaction_type = 'apply'
              AND ui.job_id::text NOT IN (
                  SELECT job_id::text 
                  FROM user_interactions 
                  WHERE user_id = %s
              )
        """, (similar_user_ids, user_id))
        available_applies = cur.fetchone()['count']
        print(f"  Available applies (after exclusion): {available_applies}")
        
        # å®Ÿéš›ã®ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
        cur.execute("""
            SELECT 
                ui.job_id,
                cp.job_title,
                cp.location_prefecture,
                cp.salary_min,
                cp.salary_max,
                cd.company_name,
                COUNT(*) as apply_count,
                MAX(ui.created_at) as latest_apply
            FROM user_interactions ui
            JOIN company_profile cp ON ui.job_id::text = cp.id::text
            JOIN company_date cd ON cp.company_id = cd.company_id
            WHERE ui.user_id = ANY(%s)
              AND ui.interaction_type = 'apply'
              AND ui.job_id::text NOT IN (
                  SELECT job_id::text 
                  FROM user_interactions 
                  WHERE user_id = %s
              )
            GROUP BY ui.job_id, cp.job_title, cp.location_prefecture, 
                     cp.salary_min, cp.salary_max, cd.company_name
            ORDER BY apply_count DESC, latest_apply DESC
            LIMIT 1
        """, (similar_user_ids, user_id))
        
        recommended_job = cur.fetchone()
        
        cur.close()
        conn.close()
        
        if recommended_job:
            print(f"\nâœ“ Found similar user applied job: {recommended_job['company_name']} / {recommended_job['job_title']}")
            return dict(recommended_job)
        else:
            print("\nâš  No applied jobs found from similar users (after exclusion)")
            return None
        
    except Exception as e:
        print(f"Error finding similar user applied job: {e}")
        import traceback
        traceback.print_exc()
        return None


def generate_similar_user_recommendation_text(user_id: int, recommended_job: Dict) -> str:
    """
    é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿œå‹Ÿæ±‚äººã«ã¤ã„ã¦ã€GPT-4ã§ææ¡ˆæ–‡ã‚’ç”Ÿæˆ
    
    Args:
        user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        recommended_job: ãŠã™ã™ã‚ã®æ±‚äººæƒ…å ±
    
    Returns:
        ææ¡ˆæ–‡
    """
    try:
        conn = get_db_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”å±¥æ­´ã‚’å–å¾—
        cur.execute("""
            SELECT dq.question_text, uqr.response_text
            FROM user_question_responses uqr
            JOIN dynamic_questions dq ON uqr.question_id = dq.id
            WHERE uqr.user_id = %s
            ORDER BY uqr.created_at
        """, (user_id,))
        
        responses = cur.fetchall()
        
        cur.close()
        conn.close()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¡ä»¶ã‚’æ•´ç†
        conditions_text = "\n".join([
            f"- {resp['question_text']}: {resp['response_text']}"
            for resp in responses
        ])
        
        prompt = f"""
ã‚ãªãŸã¯æ±‚äººãƒãƒƒãƒãƒ³ã‚°AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ä¼¼ãŸæ¡ä»¶ã§æ±‚äººã‚’æ¢ã—ã¦ã„ãŸéå»ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€å®Ÿéš›ã«å¿œå‹Ÿã—ãŸæ±‚äººã‚’è¦‹ã¤ã‘ã¾ã—ãŸã€‚

ã€ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¸Œæœ›æ¡ä»¶ã€‘
{conditions_text}

ã€éå»ã®é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¿œå‹Ÿã—ãŸæ±‚äººã€‘
- ä¼æ¥­å: {recommended_job['company_name']}
- è·ç¨®: {recommended_job['job_title']}
- å‹¤å‹™åœ°: {recommended_job['location_prefecture']}
- å¹´å: {recommended_job['salary_min']}ä¸‡ã€œ{recommended_job['salary_max']}ä¸‡
- å¿œå‹Ÿå®Ÿç¸¾: {recommended_job['apply_count']}äºº

ã€ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯ã€‘
ã“ã®æ±‚äººãŒãªãœãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãƒãƒƒãƒã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã‹ã€æ¸©ã‹ã¿ã®ã‚ã‚‹æ–‡ç« ã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
1. ã€Œã‚ãªãŸã¨ä¼¼ãŸæ¡ä»¶ã§æ±‚äººã‚’æ¢ã—ã¦ã„ãŸæ–¹ãŒã€å®Ÿéš›ã«å¿œå‹Ÿã—ãŸæ±‚äººãŒã‚ã‚Šã¾ã™ã€ã¨ã„ã†å°å…¥
2. ã“ã®æ±‚äººã®é­…åŠ›ãƒã‚¤ãƒ³ãƒˆ
3. ã€Œãœã²æ¤œè¨ã—ã¦ã¿ã¦ãã ã•ã„ã€ã¨ã„ã†å‰å‘ããªç· ã‚ããã‚Š

è‡ªç„¶ã§è¦ªã—ã¿ã‚„ã™ã„ãƒˆãƒ¼ãƒ³ã§ã€2ã€œ3æ–‡ç¨‹åº¦ã§æ›¸ã„ã¦ãã ã•ã„ã€‚
"""
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=300
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        print(f"Error generating similar user recommendation text: {e}")
        return "ã‚ãªãŸã¨ä¼¼ãŸæ¡ä»¶ã§æ±‚äººã‚’æ¢ã—ã¦ã„ãŸæ–¹ãŒã€å®Ÿéš›ã«å¿œå‹Ÿã—ãŸæ±‚äººãŒã‚ã‚Šã¾ã™ã€‚ãœã²æ¤œè¨ã—ã¦ã¿ã¦ãã ã•ã„ã€‚"


# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def extract_intent_with_ai(user_message: str) -> dict:
    """AIã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚’æŠ½å‡º"""
    prompt = f"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¦JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„:

ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€: {user_message}

æŠ½å‡ºã™ã‚‹æƒ…å ±:
- job_title: è·ç¨®
- location_prefecture: å‹¤å‹™åœ°ï¼ˆéƒ½é“åºœçœŒã®ã¿ï¼‰
- salary_min: æœ€ä½å¹´åï¼ˆæ•°å€¤ï¼‰
- ãã®ä»–ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¨€åŠã—ãŸæ¡ä»¶

å‡ºåŠ›ã¯JSONå½¢å¼ã®ã¿è¿”ã—ã¦ãã ã•ã„ã€‚
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )

        result_text = response.choices[0].message.content.strip()

        # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
        import re
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if json_match:
            result_text = json_match.group(0)

        intent = json.loads(result_text)
        return intent

    except Exception as e:
        print(f"Error extracting intent: {e}")
        return {}


def update_user_profile_with_intent(user_id: int, intent: dict):
    """æŠ½å‡ºã—ãŸæ„å›³ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
    if not intent:
        return

    # æ„å›³ãŒç©ºã¾ãŸã¯è·ç¨®ãƒ»å‹¤å‹™åœ°ãƒ»å¹´åãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    has_useful_info = any(key in intent for key in ['job_title', 'location_prefecture', 'salary_min'])
    
    if not has_useful_info:
        print("  â†’ No useful profile info in intent, skipping update")
        return

    conn = get_db_conn()
    cur = conn.cursor()

    # æ—¢å­˜ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    cur.execute("""
        SELECT job_title, location_prefecture, salary_min
        FROM user_profile
        WHERE user_id = %s
    """, (user_id,))

    profile = cur.fetchone()

    if not profile:
        cur.close()
        conn.close()
        return

    # ãƒãƒ¼ã‚¸ï¼ˆæ—¢å­˜ã®å€¤ã‚’ä¿æŒã€ç©ºã®å ´åˆã®ã¿æ›´æ–°ï¼‰
    job_title = intent.get('job_title') if intent.get('job_title') else profile[0]
    location_prefecture = intent.get('location_prefecture') if intent.get('location_prefecture') else profile[1]
    salary_min = intent.get('salary_min') if intent.get('salary_min') else profile[2]

    # æ›´æ–°
    cur.execute("""
        UPDATE user_profile
        SET job_title = %s,
            location_prefecture = %s,
            salary_min = %s,
            updated_at = CURRENT_TIMESTAMP
        WHERE user_id = %s
    """, (job_title, location_prefecture, salary_min, user_id))

    conn.commit()
    cur.close()
    conn.close()

# --- ç®¡ç†è€…æ©Ÿèƒ½: å‹•çš„è³ªå•ã®ç”Ÿæˆ ---
@app.route("/admin/generate_questions", methods=["POST"])
def admin_generate_questions():
    """æ±‚äººãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‹•çš„è³ªå•ã‚’ç”Ÿæˆï¼ˆç®¡ç†è€…ç”¨ï¼‰"""
    questions = QuestionGenerator.generate_questions_from_jobs()
    saved_count = QuestionGenerator.save_generated_questions(questions)

    return jsonify({
        "status": "success",
        "generated_questions": len(questions),
        "saved": saved_count
    })


# --- åˆæœŸåŒ–é–¢æ•°ï¼ˆã“ã“ã«è¿½åŠ ï¼‰---
def initialize_questions():
    """
    åˆæœŸè³ªå•ã‚’DBã«ç™»éŒ²ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    æ³¨æ„: æ–°ã—ã„å‹•çš„è³ªå•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€ã“ã®ãƒªã‚¹ãƒˆã¯å‚è€ƒç”¨ã¨ã—ã¦æ®‹ã—ã¦ã„ã¾ã™ãŒã€
    å®Ÿéš›ã®è³ªå•ã¯AIãŒæ±‚äººãƒ‡ãƒ¼ã‚¿ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®çŠ¶æ³ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚
    
    å›ºå®šãƒªã‚¹ãƒˆã‚’ä½¿ã„ãŸã„å ´åˆã¯ã€ã“ã®ã¾ã¾å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
    å®Œå…¨å‹•çš„ã«ã™ã‚‹å ´åˆã¯ã€ã“ã®é–¢æ•°ã‚’å®Ÿè¡Œã—ãªã„ã§ãã ã•ã„ã€‚
    """
    conn = get_db_conn()
    cur = conn.cursor()
    
    # åŸºæœ¬çš„ãªè³ªå•ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆå‚è€ƒç”¨ï¼‰
    # ã“ã‚Œã‚‰ã¯å‹•çš„ç”Ÿæˆã®ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹è³ªå•ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™
    initial_questions = [
        ('remote', 'ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯å¯èƒ½ãªæ±‚äººã‚’å¸Œæœ›ã—ã¾ã™ã‹ï¼Ÿ', 'åƒãæ–¹ã®æŸ”è»Ÿæ€§', 'boolean'),
        ('flex_time', 'ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ åˆ¶åº¦ã‚’å¸Œæœ›ã—ã¾ã™ã‹ï¼Ÿ', 'åƒãæ–¹ã®æŸ”è»Ÿæ€§', 'boolean'),
        ('side_job', 'å‰¯æ¥­å¯èƒ½ãªæ±‚äººã‚’å¸Œæœ›ã—ã¾ã™ã‹ï¼Ÿ', 'åƒãæ–¹ã®æŸ”è»Ÿæ€§', 'boolean'),
        ('overtime', 'æ®‹æ¥­æ™‚é–“ã«ã¤ã„ã¦å¸Œæœ›ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ', 'åƒãæ–¹ã®æŸ”è»Ÿæ€§', 'choice'),
        ('company_type', 'ä¼æ¥­è¦æ¨¡ã®å¸Œæœ›ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ', 'ä¼æ¥­æ–‡åŒ–ãƒ»é›°å›²æ°—', 'choice'),
        ('atmosphere', 'çµ„ç¹”ã®é›°å›²æ°—ã¯ã©ã®ã‚ˆã†ãªã‚‚ã®ãŒè‰¯ã„ã§ã™ã‹ï¼Ÿ', 'ä¼æ¥­æ–‡åŒ–ãƒ»é›°å›²æ°—', 'choice'),
        ('growth', 'ã‚­ãƒ£ãƒªã‚¢æˆé•·ã®æ©Ÿä¼šã‚’é‡è¦–ã—ã¾ã™ã‹ï¼Ÿ', 'ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹', 'boolean'),
        ('training', 'ç ”ä¿®ãƒ»ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—æ”¯æ´ã‚’é‡è¦–ã—ã¾ã™ã‹ï¼Ÿ', 'ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹', 'boolean'),
        ('promotion', 'æ˜‡é€²ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚’é‡è¦–ã—ã¾ã™ã‹ï¼Ÿ', 'ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹', 'choice'),
    ]
    
    for q_key, q_text, category, q_type in initial_questions:
        try:
            cur.execute("""
                INSERT INTO dynamic_questions (question_key, question_text, category, question_type)
                VALUES (%s, %s, %s, %s)
                ON CONFLICT (question_key) DO NOTHING
            """, (q_key, q_text, category, q_type))
        except Exception as e:
            print(f"Error inserting question: {e}")
    
    conn.commit()
    cur.close()
    conn.close()
    print("âœ“ Initial questions initialized (optional templates)")
    print("  Note: New system uses AI to generate questions dynamically")


def extract_all_job_attributes():
    """å…¨æ±‚äººã®å±æ€§ã‚’æŠ½å‡ºï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œç”¨ï¼‰"""
    conn = get_db_conn()
    cur = conn.cursor()
    cur.execute("SELECT id FROM company_profile")
    job_ids = [row[0] for row in cur.fetchall()]
    cur.close()
    conn.close()
    
    print(f"â³ Extracting attributes for {len(job_ids)} jobs...")
    
    for i, job_id in enumerate(job_ids, 1):
        try:
            JobAttributeExtractor.extract_and_save_job_attributes(job_id)
            print(f"  [{i}/{len(job_ids)}] Extracted: {job_id}")
        except Exception as e:
            print(f"  [{i}/{len(job_ids)}] Failed: {job_id} - {e}")
    
    print("âœ“ All job attributes extracted")


# --- ãƒ¡ã‚¤ãƒ³èµ·å‹•ï¼ˆã“ã“ã‹ã‚‰ï¼‰---
if __name__ == "__main__":
    # ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«åˆæœŸè³ªå•ã‚’ç™»éŒ²
    initialize_questions()
    
    # æ±‚äººå±æ€§ãŒæœªæŠ½å‡ºãªã‚‰æŠ½å‡º
    conn = get_db_conn()
    cur = conn.cursor()
    cur.execute("SELECT COUNT(*) FROM job_attributes")
    attr_count = cur.fetchone()[0]
    cur.close()
    conn.close()
    
    if attr_count == 0:
        print("âš  Job attributes not extracted. Extracting...")
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ï¼‰
        import threading
        threading.Thread(target=extract_all_job_attributes, daemon=True).start()
    else:
        print(f"âœ“ Job attributes already extracted ({attr_count} records)")
    
    app.run(debug=True, port=5002, load_dotenv=False)