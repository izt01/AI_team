"""
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ 
- å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¡Œå‹•ã‹ã‚‰æ¨è–¦
- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éå»ã®é¸å¥½ã‹ã‚‰æ¨è–¦
- scikit-learnã‚’ä½¿ã£ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«
"""

import psycopg2
from psycopg2.extras import RealDictCursor
import numpy as np
from typing import List, Dict, Any, Tuple, Optional
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
import pickle
import json


def get_db_conn():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—"""
    return psycopg2.connect(
        host="localhost", port=5432, dbname="jobmatch",
        user="devuser", password="devpass"
    )


class CollaborativeFiltering:
    """å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def find_similar_users(user_id: int, top_k: int = 10) -> List[Tuple[int, float]]:
        """
        é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆè¡Œå‹•å±¥æ­´ãƒ™ãƒ¼ã‚¹ï¼‰

        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            top_k: ä¸Šä½Käººã‚’è¿”ã™

        Returns:
            (user_id, similarity_score) ã®ãƒªã‚¹ãƒˆ
        """
        try:
            conn = get_db_conn()
            cur = conn.cursor(cursor_factory=RealDictCursor)

            # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¡Œå‹•å±¥æ­´ã‚’å–å¾—ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼Ã—æ±‚äººã®ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼‰
            cur.execute("""
                SELECT user_id, job_id, interaction_type,
                       CASE
                           WHEN interaction_type = 'apply' THEN 5.0
                           WHEN interaction_type = 'favorite' THEN 3.0
                           WHEN interaction_type = 'click' THEN 1.0
                           WHEN interaction_type = 'view' THEN 0.5
                           ELSE 0.0
                       END as score
                FROM user_interactions
                WHERE user_id IN (
                    SELECT DISTINCT user_id FROM user_interactions
                )
            """)

            interactions = cur.fetchall()
            cur.close()
            conn.close()

            if not interactions:
                return []

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼Ã—æ±‚äººã®ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰
            user_item_matrix = {}
            all_jobs = set()

            for inter in interactions:
                uid = inter['user_id']
                jid = str(inter['job_id'])  # UUIDã‚’æ–‡å­—åˆ—ã«å¤‰æ›
                score = float(inter['score'])  # Decimalã‚’floatã«å¤‰æ›

                if uid not in user_item_matrix:
                    user_item_matrix[uid] = {}

                user_item_matrix[uid][jid] = user_item_matrix[uid].get(jid, 0.0) + score
                all_jobs.add(jid)

            if user_id not in user_item_matrix:
                return []

            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ™ã‚¯ãƒˆãƒ«
            target_vector = [user_item_matrix[user_id].get(job, 0.0) for job in sorted(all_jobs)]

            # é¡ä¼¼åº¦ã‚’è¨ˆç®—
            similarities = []
            for uid, items in user_item_matrix.items():
                if uid == user_id:
                    continue

                user_vector = [items.get(job, 0.0) for job in sorted(all_jobs)]

                # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
                similarity = cosine_similarity([target_vector], [user_vector])[0][0]

                if similarity > 0.0:
                    similarities.append((uid, float(similarity)))

            # é¡ä¼¼åº¦ã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
            similarities.sort(key=lambda x: x[1], reverse=True)

            return similarities[:top_k]

        except Exception as e:
            print(f"Error finding similar users: {e}")
            import traceback
            traceback.print_exc()
            return []

    @staticmethod
    def get_recommendations_from_similar_users(user_id: int, top_k: int = 20) -> List[Tuple[str, float]]:
        """
        é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¡Œå‹•ã‹ã‚‰æ±‚äººã‚’æ¨è–¦

        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            top_k: ä¸Šä½Kä»¶ã‚’è¿”ã™

        Returns:
            (job_id, score) ã®ãƒªã‚¹ãƒˆ
        """
        try:
            # é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¦‹ã¤ã‘ã‚‹
            similar_users = CollaborativeFiltering.find_similar_users(user_id, top_k=10)

            if not similar_users:
                return []

            conn = get_db_conn()
            cur = conn.cursor(cursor_factory=RealDictCursor)

            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ—¢ã«ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã—ãŸæ±‚äººã‚’å–å¾—
            cur.execute("""
                SELECT DISTINCT job_id FROM user_interactions
                WHERE user_id = %s
            """, (user_id,))

            interacted_jobs = set([str(row['job_id']) for row in cur.fetchall()])

            # é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã—ãŸæ±‚äººã‚’å–å¾—
            similar_user_ids = [uid for uid, _ in similar_users]
            similarities_dict = {uid: sim for uid, sim in similar_users}

            if not similar_user_ids:
                cur.close()
                conn.close()
                return []

            cur.execute("""
                SELECT user_id, job_id, interaction_type,
                       CASE
                           WHEN interaction_type = 'apply' THEN 5.0
                           WHEN interaction_type = 'favorite' THEN 3.0
                           WHEN interaction_type = 'click' THEN 1.0
                           WHEN interaction_type = 'view' THEN 0.5
                           ELSE 0.0
                       END as score
                FROM user_interactions
                WHERE user_id = ANY(%s)
            """, (similar_user_ids,))

            recommendations = cur.fetchall()
            cur.close()
            conn.close()

            # ã‚¹ã‚³ã‚¢ã‚’é›†è¨ˆï¼ˆé¡ä¼¼åº¦ã§é‡ã¿ä»˜ã‘ï¼‰
            job_scores = {}
            for rec in recommendations:
                jid = str(rec['job_id'])
                
                # æ—¢ã«ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³æ¸ˆã¿ã®æ±‚äººã¯ã‚¹ã‚­ãƒƒãƒ—
                if jid in interacted_jobs:
                    continue
                    
                uid = rec['user_id']
                score = float(rec['score'])
                similarity = similarities_dict.get(uid, 0.0)

                weighted_score = score * similarity
                job_scores[jid] = job_scores.get(jid, 0.0) + weighted_score

            # ã‚¹ã‚³ã‚¢ã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
            sorted_jobs = sorted(job_scores.items(), key=lambda x: x[1], reverse=True)

            return sorted_jobs[:top_k]

        except Exception as e:
            print(f"Error getting recommendations from similar users: {e}")
            import traceback
            traceback.print_exc()
            return []


class ContentBasedFiltering:
    """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def get_recommendations_from_user_profile(user_id: int, top_k: int = 20, previous_job_ids: List[str] = None) -> List[Tuple[str, float]]:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ±‚äººã‚’æ¨è–¦ï¼ˆç´¯ç©çµã‚Šè¾¼ã¿å¯¾å¿œç‰ˆï¼‰

        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            top_k: ä¸Šä½Kä»¶ã‚’è¿”ã™
            previous_job_ids: å‰å›ã®çµæœã®IDãƒªã‚¹ãƒˆ

        Returns:
            (job_id, score) ã®ãƒªã‚¹ãƒˆ
        """
        try:
            conn = get_db_conn()
            cur = conn.cursor(cursor_factory=RealDictCursor)

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            cur.execute("""
                SELECT job_title, location_prefecture, salary_min
                FROM user_profile
                WHERE user_id = %s
            """, (user_id,))

            profile = cur.fetchone()

            if not profile:
                print(f"âš  No profile found for user_id: {user_id}")
                cur.close()
                conn.close()
                return []

            print(f"User profile: {profile}")

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•å›ç­”ã‚’å–å¾—
            cur.execute("""
                SELECT dq.question_key, dq.category, uqr.normalized_response
                FROM user_question_responses uqr
                JOIN dynamic_questions dq ON uqr.question_id = dq.id
                WHERE uqr.user_id = %s
            """, (user_id,))

            responses = cur.fetchall()
            print(f"User responses: {len(responses)} answers")

            # å›ç­”ã‚’è¾æ›¸ã«æ•´ç†ï¼ˆæ”¹å–„ç‰ˆï¼‰
            user_preferences = {}
            
            # â˜…â˜…â˜… question_keyã®è‡ªå‹•æ­£è¦åŒ–ï¼ˆå …ç‰¢ç‰ˆï¼‰ â˜…â˜…â˜…
            # æ—¢çŸ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            known_keywords = {
                'remote': ['remote', 'ãƒªãƒ¢ãƒ¼ãƒˆ', 'ãƒ†ãƒ¬ãƒ¯ãƒ¼ã‚¯', 'wfh', 'work_from_home'],
                'flex_time': ['flex', 'ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹', 'flexible', 'æŸ”è»Ÿ'],
                'side_job': ['side', 'å‰¯æ¥­', 'ã‚µã‚¤ãƒ‰', 'å…¼æ¥­'],
                'company_size': ['size', 'è¦æ¨¡', 'ä¼æ¥­è¦æ¨¡', 'company_size'],
                'company_type': ['type', 'ã‚¿ã‚¤ãƒ—', 'ãƒ™ãƒ³ãƒãƒ£ãƒ¼', 'å¤§ä¼æ¥­', 'startup'],
                'overtime': ['overtime', 'æ®‹æ¥­', 'åŠ´åƒæ™‚é–“'],
                'atmosphere': ['atmosphere', 'é›°å›²æ°—', 'æ–‡åŒ–', 'culture'],
                'training': ['training', 'ç ”ä¿®', 'æ•™è‚²', 'education'],
                'growth': ['growth', 'æˆé•·', 'ã‚­ãƒ£ãƒªã‚¢', 'career'],
                'promotion': ['promotion', 'æ˜‡é€²', 'æ˜‡æ ¼']
            }
            
            def normalize_key(original_key: str) -> str:
                """question_keyã‚’è‡ªå‹•çš„ã«æ­£è¦åŒ–"""
                key_lower = original_key.lower()
                
                # æ—¢çŸ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ãƒãƒƒãƒã™ã‚‹ã‹ç¢ºèª
                for standard_key, keywords in known_keywords.items():
                    if any(kw in key_lower for kw in keywords):
                        return standard_key
                
                # ãƒãƒƒãƒã—ãªã„å ´åˆã¯å…ƒã®ã‚­ãƒ¼ã‚’è¿”ã™
                return original_key
            
            for resp in responses:
                original_key = resp['question_key']
                # è‡ªå‹•æ­£è¦åŒ–
                key = normalize_key(original_key)
                value = resp['normalized_response'].strip().lower()
                
                if original_key != key:
                    print(f"  ğŸ”„ Normalized '{original_key}' â†’ '{key}'")
                
                # â˜…â˜…â˜… ãƒ†ã‚­ã‚¹ãƒˆè§£é‡ˆãŒå¿…è¦ãªé …ç›®ã®ãƒªã‚¹ãƒˆ â˜…â˜…â˜…
                text_interpretation_keys = ['company_type', 'company_size', 'overtime', 'atmosphere', 'promotion']
                
                if key in text_interpretation_keys:
                    # ãƒ†ã‚­ã‚¹ãƒˆã®ã¾ã¾ä¿å­˜
                    user_preferences[key] = value
                    print(f"  â†’ Stored text '{value}' for {key}")
                    continue
                
                # â˜…â˜…â˜… ãã®ä»–ã®é …ç›®ã¯çœŸå½å€¤åˆ¤å®šï¼ˆå¼·åŒ–ç‰ˆï¼‰ â˜…â˜…â˜…
                positive_keywords = [
                    'ã¯ã„', 'yes', 'hai', 'ã™ã‚‹', 'å¸Œæœ›ã™ã‚‹', 'å¸Œæœ›ã—ã¾ã™', 'å¸Œæœ›ã§ã™', 
                    'ã„ã„ã§ã™', 'ã„ã„', 'è‰¯ã„', 'ãŒã„ã„', 'ã§ãã‚‹', 'å¯èƒ½', 'ã—ãŸã„',
                    'ã‚ã‚‹', 'ã‚ã‚Š', 'ã‚ã‚ŠãŒã„ã„', 'é­…åŠ›çš„', 'å¤§åˆ‡', 'å„ªå…ˆ',
                    'å°‘ãªã‚', 'å°‘ãªã„', 'ãƒªãƒ¢ãƒ¼ãƒˆ', 'ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹', 'å¤§ä¼æ¥­', 'å¤§æ‰‹',
                    'æ´»æ°—', 'ãƒãƒ£ãƒ¬ãƒ³ã‚¸', 'æˆé•·', 'ç ”ä¿®', 'æ˜‡é€²', 'å¤šã„', 'èˆˆå‘³'
                ]
                
                negative_keywords = [
                    'ã„ã„ãˆ', 'no', 'ã—ãªã„', 'å¸Œæœ›ã—ãªã„', 'ä¸è¦', 'ãªãã¦ã‚‚',
                    'å¤§ä¸ˆå¤«', 'è€ƒãˆãªã„', 'é‡è¦–ã—ãªã„', 'ã§ããªãã¦ã‚‚', 'ç‰¹ã«', 'ãªã„', 
                    'ãªã„ã§ã™', 'èˆˆå‘³ãªã„', 'èˆˆå‘³ã¯ãªã„'
                ]
                
                # â˜…â˜…â˜… æ›–æ˜§ãªå›ç­”ï¼ˆã©ã¡ã‚‰ã§ã‚‚ãªã„ï¼‰ã‚’æ¤œå‡º â˜…â˜…â˜…
                neutral_keywords = [
                    'ã‚ªãƒ—ã‚·ãƒ§ãƒ³', 'ã©ã¡ã‚‰ã§ã‚‚', 'ã“ã ã‚ã‚‰ãªã„', 'ã‚ã‚Œã°', 'ãªãã¦ã‚‚',
                    'ã¾ã‚', 'ã§ãã‚Œã°', 'ç‰¹ã«æ°—ã«ã—ãªã„', 'æ°—ã«ã—ãªã„'
                ]
                
                is_neutral = any(kw in value for kw in neutral_keywords)
                is_positive = any(kw in value for kw in positive_keywords)
                is_negative = any(kw in value for kw in negative_keywords)
                
                if is_neutral:
                    # ã©ã¡ã‚‰ã§ã‚‚ãªã„å ´åˆã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãªã„ï¼ˆNoneã‚’ä¿å­˜ï¼‰
                    user_preferences[key] = None
                    print(f"  âšª Interpreted '{value}' as NEUTRAL (no filter) for {key}")
                elif is_positive and not is_negative:
                    user_preferences[key] = True
                    print(f"  âœ“ Interpreted '{value}' as TRUE for {key}")
                elif is_negative:
                    user_preferences[key] = False
                    print(f"  âœ— Interpreted '{value}' as FALSE for {key}")
                else:
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒã—ãªã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆã®ã¾ã¾ä¿å­˜
                    user_preferences[key] = value
                    print(f"  â†’ Stored text '{value}' for {key}")

            print(f"\nFinal user preferences: {user_preferences}")

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ—¢ã«ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã—ãŸæ±‚äººã‚’é™¤å¤–
            cur.execute("""
                SELECT DISTINCT job_id FROM user_interactions
                WHERE user_id = %s AND interaction_type IN ('apply', 'favorite')
            """, (user_id,))

            interacted_jobs = set([str(row['job_id']) for row in cur.fetchall()])
            print(f"Excluding {len(interacted_jobs)} already interacted jobs")

            # åŸºæœ¬æ¡ä»¶ã«åˆã†æ±‚äººã‚’æ¤œç´¢
            titles = [t.strip() for t in profile['job_title'].split(',') if t.strip()] if profile['job_title'] else []
            locations = [l.strip() for l in profile['location_prefecture'].split(',') if l.strip()] if profile['location_prefecture'] else []
            salary_min = int(profile['salary_min']) if profile['salary_min'] else 0

            print(f"Search criteria - titles: {titles}, locations: {locations}, salary_min: {salary_min}")

            conditions = []
            params = []

            # è·ç¨®ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰
            if titles:
                title_conditions = []
                for title in titles:
                    title_conditions.append("cp.job_title ILIKE %s")
                    params.append(f"%{title}%")
                conditions.append(f"({' OR '.join(title_conditions)})")

            # å‹¤å‹™åœ°ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰
            if locations:
                location_conditions = []
                for loc in locations:
                    location_conditions.append("cp.location_prefecture ILIKE %s")
                    params.append(f"%{loc}%")
                conditions.append(f"({' OR '.join(location_conditions)})")

            # å¹´å
            if salary_min > 0:
                conditions.append("cp.salary_min >= %s")
                params.append(salary_min)

            # æ—¢ã«ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã—ãŸæ±‚äººã‚’é™¤å¤–
            if interacted_jobs:
                conditions.append("cp.id::text NOT IN %s")
                params.append(tuple(interacted_jobs))

            # â˜…â˜…â˜… å‰å›ã®çµæœãŒã‚ã‚‹å ´åˆã€ãã‚Œã‚’æ¡ä»¶ã«è¿½åŠ  â˜…â˜…â˜…
            if previous_job_ids:
                conditions.append("cp.id::text = ANY(%s)")
                params.append(previous_job_ids)
                print(f"ğŸ” Filtering from previous {len(previous_job_ids)} jobs")

            print("\n=== Applying Multi-Axis Filters ===")

            # â˜…â˜…â˜… å¤šè»¸ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆNULL/unknowné™¤å¤–ç‰ˆï¼‰ â˜…â˜…â˜…

            # ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆTrue/Falseä¸¡æ–¹å¯¾å¿œï¼‰
            if user_preferences.get('remote') == True:
                conditions.append("ja.work_flexibility->>'remote' = 'true'")
                print("ğŸ” Filtering: remote = true")
            elif user_preferences.get('remote') == False:
                conditions.append("ja.work_flexibility->>'remote' = 'false'")
                print("ğŸ” Filtering: remote = false")

            # ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ ï¼ˆTrue/Falseä¸¡æ–¹å¯¾å¿œï¼‰
            if user_preferences.get('flex_time') == True:
                conditions.append("ja.work_flexibility->>'flex_time' = 'true'")
                print("ğŸ” Filtering: flex_time = true")
            elif user_preferences.get('flex_time') == False:
                conditions.append("ja.work_flexibility->>'flex_time' = 'false'")
                print("ğŸ” Filtering: flex_time = false")

            # å‰¯æ¥­ï¼ˆTrue/Falseä¸¡æ–¹å¯¾å¿œï¼‰
            if user_preferences.get('side_job') == True:
                conditions.append("ja.work_flexibility->>'side_job' = 'true'")
                print("ğŸ” Filtering: side_job = true")
            elif user_preferences.get('side_job') == False:
                conditions.append("ja.work_flexibility->>'side_job' = 'false'")
                print("ğŸ” Filtering: side_job = false")

            # â˜…â˜…â˜… ä¼æ¥­è¦æ¨¡ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆè¿½åŠ ï¼‰ â˜…â˜…â˜…
            if 'company_type' in user_preferences:
                user_size = user_preferences['company_type']

                if isinstance(user_size, str):
                    if any(kw in user_size for kw in ['å¤§ãã„', 'å¤§ä¼æ¥­', 'å¤§æ‰‹', 'å®‰å®š', 'å¤§è¦æ¨¡', 'ç’°å¢ƒ']):
                        conditions.append("ja.company_culture->>'size' = 'large'")
                        print("ğŸ” Filtering: company size = large")
                    elif any(kw in user_size for kw in ['å°', 'ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—', 'ãƒ™ãƒ³ãƒãƒ£ãƒ¼', 'å°è¦æ¨¡', 'ä¸­å°', 'ä¸­å …']):
                        conditions.append("ja.company_culture->>'size' IN ('small', 'medium')")
                        conditions.append("ja.company_culture->>'size' != 'unknown'")
                        print("ğŸ” Filtering: company size = small/medium (excluding unknown)")

            # â˜…â˜…â˜… æ®‹æ¥­æ™‚é–“ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆè¿½åŠ ï¼‰ â˜…â˜…â˜…
            if 'overtime' in user_preferences:
                user_overtime = user_preferences['overtime']

                if isinstance(user_overtime, str):
                    if any(kw in user_overtime for kw in ['å°‘ãª', 'å°‘ãªã„', '10æ™‚é–“', 'çŸ­', 'ç„¡ã—']):
                        conditions.append("ja.work_flexibility->>'overtime' = 'low'")
                        print("ğŸ” Filtering: overtime = low")

            # ç ”ä¿®ï¼ˆTrue/Falseä¸¡æ–¹å¯¾å¿œï¼‰
            if user_preferences.get('training') == True:
                conditions.append("ja.career_path->>'training' = 'true'")
                print("ğŸ” Filtering: training = true")
            elif user_preferences.get('training') == False:
                conditions.append("ja.career_path->>'training' = 'false'")
                print("ğŸ” Filtering: training = false")

            # ã‚­ãƒ£ãƒªã‚¢æˆé•·ï¼ˆTrue/Falseä¸¡æ–¹å¯¾å¿œï¼‰
            if user_preferences.get('growth') == True:
                conditions.append("ja.career_path->>'growth_opportunities' = 'true'")
                print("ğŸ” Filtering: growth = true")
            elif user_preferences.get('growth') == False:
                conditions.append("ja.career_path->>'growth_opportunities' = 'false'")
                print("ğŸ” Filtering: growth = false")

            # é›°å›²æ°—ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if 'atmosphere' in user_preferences:
                user_atmos = user_preferences['atmosphere']

                if isinstance(user_atmos, str):
                    if any(kw in user_atmos for kw in ['æ´»æ°—', 'ãƒãƒ£ãƒ¬ãƒ³ã‚¸', 'æŒ‘æˆ¦']):
                        conditions.append("ja.company_culture->>'atmosphere' = 'challenging'")
                        conditions.append("ja.company_culture->>'atmosphere' != 'unknown'")
                        print("ğŸ” Filtering: atmosphere = challenging (excluding unknown)")

            # æ˜‡é€²ã‚¹ãƒ”ãƒ¼ãƒ‰ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if 'promotion' in user_preferences:
                user_promo = user_preferences['promotion']

                if isinstance(user_promo, str):
                    if any(kw in user_promo for kw in ['æ—©ã„', 'é€Ÿã„', 'å¤šã„', 'å„ªå…ˆ']):
                        conditions.append("ja.career_path->>'promotion_speed' = 'fast'")
                        conditions.append("ja.career_path->>'promotion_speed' != 'unknown'")
                        print("ğŸ” Filtering: promotion_speed = fast (excluding unknown)")
            
            # â˜…â˜…â˜… å…¨ã¦ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã‚’è¿½åŠ ã—ãŸå¾Œã«where_clauseã‚’å®šç¾© â˜…â˜…â˜…
            where_clause = " AND ".join(conditions) if conditions else "1=1"

            # æ±‚äººã¨å±æ€§ã‚’å–å¾—ï¼ˆINNER JOIN + NULLé™¤å¤–ï¼‰
            query = f"""
                SELECT cp.id, cp.job_title, cp.location_prefecture,
                       cp.salary_min, cp.salary_max,
                       cd.company_name,
                       ja.company_culture, ja.work_flexibility, ja.career_path
                FROM company_profile cp
                JOIN company_date cd ON cp.company_id = cd.company_id
                INNER JOIN job_attributes ja ON cp.id::text = ja.job_id::text
                WHERE {where_clause}
                  AND ja.work_flexibility IS NOT NULL
                  AND ja.company_culture IS NOT NULL
                  AND ja.career_path IS NOT NULL
            """
            print(f"\nSQL Params: {params}")

            cur.execute(query, params)
            jobs = cur.fetchall()

            print(f"\nâœ“ Found {len(jobs)} jobs matching ALL filter criteria\n")

            cur.close()
            conn.close()

            if not jobs:
                print("âš  No jobs found after filtering")
                return []

            # ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆå¤šè»¸è©•ä¾¡ï¼‰
            recommendations = []
            for job in jobs:
                score = 1.0  # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢

                # åŸºæœ¬æ¡ä»¶ã®ãƒãƒƒãƒ
                for title in titles:
                    if title.lower() in job['job_title'].lower():
                        score += 3.0

                for loc in locations:
                    if loc.lower() in job['location_prefecture'].lower():
                        score += 2.0

                if int(job['salary_min']) >= salary_min:
                    score += 2.0

                # å¤šè»¸è©•ä¾¡ã§ã®ãƒãƒƒãƒãƒ³ã‚°
                if job.get('work_flexibility'):
                    work_flex = job['work_flexibility']
                    
                    # ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯
                    if user_preferences.get('remote') == True and work_flex.get('remote') == True:
                        score += 5.0
                    elif user_preferences.get('remote') == False and work_flex.get('remote') == False:
                        score += 2.0
                    
                    # ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ 
                    if user_preferences.get('flex_time') == True and work_flex.get('flex_time') == True:
                        score += 4.0
                    
                    # å‰¯æ¥­
                    if user_preferences.get('side_job') == True and work_flex.get('side_job') == True:
                        score += 4.0
                    
                    # æ®‹æ¥­
                    if 'overtime' in user_preferences:
                        user_overtime = user_preferences['overtime']
                        job_overtime = work_flex.get('overtime', '')
                        
                        if isinstance(user_overtime, str) and 'å°‘ãª' in user_overtime and job_overtime == 'low':
                            score += 5.0
                        elif isinstance(user_overtime, str) and 'æ™®é€š' in user_overtime and job_overtime == 'medium':
                            score += 3.0

                # ä¼æ¥­æ–‡åŒ–
                if job.get('company_culture'):
                    culture = job['company_culture']
                    
                    # ä¼æ¥­è¦æ¨¡
                    if 'company_type' in user_preferences:
                        user_size = user_preferences['company_type']
                        job_size = culture.get('size', '')
                        
                        if isinstance(user_size, str):
                            if any(kw in user_size for kw in ['å¤§ãã„', 'å¤§ä¼æ¥­', 'å¤§æ‰‹', 'å®‰å®š', 'å¤§è¦æ¨¡', 'ç’°å¢ƒ']) and job_size == 'large':
                                score += 6.0
                            elif any(kw in user_size for kw in ['å°', 'ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—', 'ãƒ™ãƒ³ãƒãƒ£ãƒ¼']) and job_size in ['small', 'medium']:
                                score += 5.0
                    
                    # é›°å›²æ°—
                    if 'atmosphere' in user_preferences:
                        user_atmos = user_preferences['atmosphere']
                        job_atmos = culture.get('atmosphere', '')
                        
                        if isinstance(user_atmos, str) and any(kw in user_atmos for kw in ['æ´»æ°—', 'ãƒãƒ£ãƒ¬ãƒ³ã‚¸']):
                            if job_atmos == 'challenging':
                                score += 5.0

                # ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹
                if job.get('career_path'):
                    career = job['career_path']
                    
                    # æˆé•·æ©Ÿä¼š
                    if user_preferences.get('growth') == True and career.get('growth_opportunities') == True:
                        score += 5.0
                    
                    # ç ”ä¿®
                    if user_preferences.get('training') == True and career.get('training') == True:
                        score += 5.0
                    
                    # æ˜‡é€²ã‚¹ãƒ”ãƒ¼ãƒ‰
                    if 'promotion' in user_preferences:
                        user_promo = user_preferences['promotion']
                        job_promo = career.get('promotion_speed', '')
                        
                        if isinstance(user_promo, str) and 'æ—©ã„' in user_promo and job_promo == 'fast':
                            score += 6.0
                        elif isinstance(user_promo, str) and 'ã‚†ã£ãã‚Š' in user_promo and job_promo == 'slow':
                            score += 4.0

                recommendations.append((str(job['id']), score))

            # ã‚¹ã‚³ã‚¢ã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
            recommendations.sort(key=lambda x: x[1], reverse=True)

            print(f"Returning {len(recommendations) if top_k is None else len(recommendations[:top_k])} recommendations")
            return recommendations if top_k is None else recommendations[:top_k]

        except Exception as e:
            print(f"Error getting recommendations from user profile: {e}")
            import traceback
            traceback.print_exc()
            return []


class HybridRecommender:
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚¯ãƒ©ã‚¹ï¼ˆå”èª¿ + ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹ + å¤šè»¸è©•ä¾¡ï¼‰"""

    @staticmethod
    def get_hybrid_recommendations(user_id: int, top_k: int = 20, previous_job_ids: List[str] = None) -> List[Dict[str, Any]]:
        """
        ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç´¯ç©çµã‚Šè¾¼ã¿å¯¾å¿œï¼‰

        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            top_k: ä¸Šä½Kä»¶ã‚’è¿”ã™ï¼ˆNoneã®å ´åˆã¯å…¨ä»¶è¿”ã™ï¼‰
            previous_job_ids: å‰å›ã®çµæœã®IDãƒªã‚¹ãƒˆï¼ˆNoneã®å ´åˆã¯å…¨ä½“ã‹ã‚‰æ¤œç´¢ï¼‰

        Returns:
            æ¨è–¦æ±‚äººã®ãƒªã‚¹ãƒˆ
        """
        try:
            print(f"\n=== Hybrid Recommendation for user_id: {user_id} ===")
        
            if previous_job_ids:
                print(f"Filtering from previous {len(previous_job_ids)} jobs")
        
            # å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®æ¨è–¦
            cf_recs = CollaborativeFiltering.get_recommendations_from_similar_users(user_id, top_k=top_k)
            print(f"CF recommendations: {len(cf_recs)} jobs")

            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦
            cb_recs = ContentBasedFiltering.get_recommendations_from_user_profile(
                user_id, 
                top_k=top_k,
                previous_job_ids=previous_job_ids
            )
            print(f"CB recommendations: {len(cb_recs)} jobs")

            # ã‚¹ã‚³ã‚¢ã‚’ãƒãƒ¼ã‚¸ï¼ˆé‡ã¿ä»˜ã‘ï¼‰
            cf_weight = 0.4
            cb_weight = 0.6

            combined_scores = {}

            for job_id, score in cf_recs:
                combined_scores[job_id] = combined_scores.get(job_id, 0.0) + score * cf_weight

            for job_id, score in cb_recs:
                combined_scores[job_id] = combined_scores.get(job_id, 0.0) + score * cb_weight

            print(f"Combined scores: {len(combined_scores)} unique jobs")

            # ã‚¹ã‚³ã‚¢ã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
            sorted_jobs = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)

            # æ±‚äººæƒ…å ±ã‚’å–å¾—
            if not sorted_jobs:
                print("âš  No jobs after combining scores")
                return []

            conn = get_db_conn()
            cur = conn.cursor(cursor_factory=RealDictCursor)

            job_ids = [jid for jid, _ in (sorted_jobs if top_k is None else sorted_jobs[:top_k])]
            print(f"Fetching details for {len(job_ids)} jobs")

            cur.execute("""
                SELECT cp.id, cp.job_title, cp.location_prefecture,
                       cp.salary_min, cp.salary_max,
                       cd.company_name
                FROM company_profile cp
                JOIN company_date cd ON cp.company_id = cd.company_id
                WHERE cp.id::text = ANY(%s)
            """, (job_ids,))

            jobs = cur.fetchall()
            print(f"Found {len(jobs)} job details")
        
            cur.close()
            conn.close()

            # ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸
            jobs_dict = {str(job['id']): dict(job) for job in jobs}
            results = []

            for job_id, score in (sorted_jobs if top_k is None else sorted_jobs[:top_k]):
                if job_id in jobs_dict:
                    job = jobs_dict[job_id]
                    job['recommendation_score'] = score
                    results.append(job)

            print(f"Final results: {len(results)} jobs\n")
            return results

        except Exception as e:
            print(f"Error getting hybrid recommendations: {e}")
            import traceback
            traceback.print_exc()
            return []


class MLModelScorer:
    """æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""

    def __init__(self, model_version: str = "v1.0"):
        self.model_version = model_version
        self.model = None
        self.scaler = None

    def extract_features(self, user_id: int, job_id: str) -> Optional[np.ndarray]:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨æ±‚äººã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º

        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            job_id: æ±‚äººID (UUIDæ–‡å­—åˆ—)

        Returns:
            ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«
        """
        try:
            conn = get_db_conn()
            cur = conn.cursor(cursor_factory=RealDictCursor)

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
            cur.execute("""
                SELECT job_title, location_prefecture, salary_min
                FROM user_profile
                WHERE user_id = %s
            """, (user_id,))
            user_profile = cur.fetchone()

            # æ±‚äººæƒ…å ±
            cur.execute("""
                SELECT cp.job_title, cp.location_prefecture, cp.salary_min, cp.salary_max,
                       cp.click_count, cp.favorite_count, cp.apply_count
                FROM company_profile cp
                WHERE cp.id::text = %s
            """, (job_id,))
            job = cur.fetchone()

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¡Œå‹•ã‚µãƒãƒªãƒ¼
            cur.execute("""
                SELECT * FROM user_interaction_summary
                WHERE user_id = %s
            """, (user_id,))
            user_summary = cur.fetchone()

            cur.close()
            conn.close()

            if not user_profile or not job:
                return None

            # ç‰¹å¾´é‡ã‚’æ§‹ç¯‰
            features = []

            # 1. å¹´åã®ãƒãƒƒãƒåº¦
            salary_match = 1.0 if int(job['salary_min']) >= int(user_profile['salary_min']) else 0.0
            features.append(salary_match)

            # 2. å¹´åã®å·®ï¼ˆæ­£è¦åŒ–ï¼‰
            salary_diff = (int(job['salary_min']) - int(user_profile['salary_min'])) / 1000.0
            features.append(salary_diff)

            # 3. è·ç¨®ã®ãƒãƒƒãƒï¼ˆç°¡æ˜“çš„ã«æ–‡å­—åˆ—ä¸€è‡´ï¼‰
            title_match = 1.0 if user_profile['job_title'].lower() in job['job_title'].lower() else 0.0
            features.append(title_match)

            # 4. å‹¤å‹™åœ°ã®ãƒãƒƒãƒ
            location_match = 1.0 if user_profile['location_prefecture'].lower() in job['location_prefecture'].lower() else 0.0
            features.append(location_match)

            # 5. æ±‚äººã®äººæ°—åº¦ï¼ˆã‚¯ãƒªãƒƒã‚¯æ•°ã€ãŠæ°—ã«å…¥ã‚Šæ•°ã€å¿œå‹Ÿæ•°ï¼‰
            features.append(int(job.get('click_count', 0)))
            features.append(int(job.get('favorite_count', 0)))
            features.append(int(job.get('apply_count', 0)))

            # 6. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£
            if user_summary:
                features.append(int(user_summary.get('total_clicks', 0)))
                features.append(int(user_summary.get('total_favorites', 0)))
                features.append(int(user_summary.get('total_applies', 0)))
            else:
                features.extend([0, 0, 0])

            return np.array(features).reshape(1, -1)

        except Exception as e:
            print(f"Error extracting features: {e}")
            return None

    def train_model(self, training_data: List[Tuple[int, str, int]]) -> bool:
        """
        Args:
            training_data: (user_id, job_id, label) ã®ãƒªã‚¹ãƒˆ
                        label: 1=å¿œå‹Ÿ/ãŠæ°—ã«å…¥ã‚Š, 0=ã‚¯ãƒªãƒƒã‚¯ã®ã¿/é–²è¦§ã®ã¿

        Returns:
                æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        try:
            X = []
            y = []

            for user_id, job_id, label in training_data:
                features = self.extract_features(user_id, job_id)
                if features is not None:
                    X.append(features.flatten())
                    y.append(label)

            if not X:
                return False

            X = np.array(X)
            y = np.array(y)

            # ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            self.scaler = StandardScaler()
            X_scaled = self.scaler.fit_transform(X)

            # ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ãƒ¢ãƒ‡ãƒ«
            self.model = LogisticRegression(max_iter=1000, random_state=42)
            self.model.fit(X_scaled, y)

            return True

        except Exception as e:
            print(f"Error training model: {e}")
            return False

    def predict_score(self, user_id: int, job_id: str) -> float:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã‚¹ã‚³ã‚¢ã‚’äºˆæ¸¬

        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            job_id: æ±‚äººID (UUIDæ–‡å­—åˆ—)

        Returns:
            äºˆæ¸¬ã‚¹ã‚³ã‚¢ï¼ˆ0.0ã€œ1.0ï¼‰
        """
        if self.model is None or self.scaler is None:
            return 0.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        try:
            features = self.extract_features(user_id, job_id)
            if features is None:
                return 0.5

            features_scaled = self.scaler.transform(features)
            score = self.model.predict_proba(features_scaled)[0][1]  # ã‚¯ãƒ©ã‚¹1ã®ç¢ºç‡

            return float(score)

        except Exception as e:
            print(f"Error predicting score: {e}")
            return 0.5

    def save_model(self, filepath: str) -> bool:
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        try:
            with open(filepath, 'wb') as f:
                pickle.dump({'model': self.model, 'scaler': self.scaler, 'version': self.model_version}, f)
            return True
        except Exception as e:
            print(f"Error saving model: {e}")
            return False

    def load_model(self, filepath: str) -> bool:
        """ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(filepath, 'rb') as f:
                data = pickle.load(f)
                self.model = data['model']
                self.scaler = data['scaler']
                self.model_version = data.get('version', 'unknown')
            return True
        except Exception as e:
            print(f"Error loading model: {e}")
            return False