"""
é€²åŒ–å‹AIæ±‚äººãƒãƒƒãƒãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ  - å‹•çš„è³ªå•ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« v3.0

ã€ä¸»è¦æ©Ÿèƒ½ã€‘
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç‰¹æ€§ã«å¿œã˜ãŸå®Œå…¨å‹•çš„è³ªå•ç”Ÿæˆ
2. éå»ã®ä¼šè©±å±¥æ­´ã‚’è¸ã¾ãˆãŸæ·±æ˜ã‚Šè³ªå•
3. ä¼šè©±ã‚¿ãƒ¼ãƒ³æ•°ã«å¿œã˜ãŸè³ªå•ã‚¿ã‚¤ãƒ—ã®å¤‰åŒ–
4. è“„ç©ã•ã‚ŒãŸæƒ…å ±ã‚’æ´»ç”¨ã—ãŸè³ªå•ç”Ÿæˆ
5. å€™è£œæ±‚äººã®åˆ†å¸ƒã«åŸºã¥ãè³ªå•ç”Ÿæˆ
"""

from openai import OpenAI
import json
import os
from typing import Dict, Any, Optional, List
from db_config import get_db_conn
from psycopg2.extras import RealDictCursor


class EvolvingQuestionGenerator:
    def __init__(self):
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    def generate_next_question(
        self,
        user_id: int,
        session_id: str,
        conversation_turn: int,
        candidates: List[Dict],
        accumulated_insights: Dict,
        user_last_message: str
    ) -> str:
        """æ®µéšçš„ãªè³ªå•ç”Ÿæˆ"""
            
        # ğŸ”¥ æ®µéš1: åŸºæœ¬æƒ…å ±ï¼ˆ1-5ã‚¿ãƒ¼ãƒ³ï¼‰
        if conversation_turn <= 5:
            if conversation_turn == 1:
                focus = "åŸºæœ¬çš„ãªåƒãæ–¹ã®å¸Œæœ›ï¼ˆãƒªãƒ¢ãƒ¼ãƒˆã€ãƒãƒ¼ãƒ ã€ç’°å¢ƒï¼‰"
            elif conversation_turn == 2:
                focus = "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨é€£æºã®ã‚¹ã‚¿ã‚¤ãƒ«"
            elif conversation_turn == 3:
                focus = "è·å ´ã®æ–‡åŒ–ã¨é›°å›²æ°—"
            elif conversation_turn == 4:
                focus = "å…·ä½“çš„ãªãƒ„ãƒ¼ãƒ«ã¨æ‰‹æ³•"
            else:  # conversation_turn == 5
                focus = "ã¾ã¨ã‚ã¨ç¢ºèª"
            
        # ğŸ”¥ æ®µéš2: è©³ç´°æƒ…å ±ï¼ˆ6-7ã‚¿ãƒ¼ãƒ³ï¼‰
        elif conversation_turn <= 7:
            if conversation_turn == 6:
                focus = "ã‚¹ã‚­ãƒ«ã¨æˆé•·ã®æ©Ÿä¼š"
            else:  # conversation_turn == 7
                focus = "åƒãæ–¹ã®æŸ”è»Ÿæ€§ã¨æ¡ä»¶"
        
        # ğŸ”¥ æ®µéš3: æœ€çµ‚èª¿æ•´ï¼ˆ8-9ã‚¿ãƒ¼ãƒ³ï¼‰
        elif conversation_turn <= 9:
            if conversation_turn == 8:
                focus = "å¦¥å”ç‚¹ã¨å„ªå…ˆé †ä½"
            else:  # conversation_turn == 9
                focus = "æœ€çµ‚ç¢ºèªã¨æœŸå¾…"
            
        # ğŸ”¥ æ®µéš4: ç·Šæ€¥æ™‚ï¼ˆ10ã‚¿ãƒ¼ãƒ³ï¼‰
        else:
            focus = "æœ€çµ‚ææ¡ˆ"
            
        # AIã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚’ä¼ãˆã¦è³ªå•ç”Ÿæˆ
        prompt = f"""ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯{focus}ã«ã¤ã„ã¦è©±ã—ã¦ã„ã¾ã™ã€‚
        ä»Šã¾ã§ã®æƒ…å ±: {accumulated_insights}
        ç›´å‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {user_last_message}
            
        è‡ªç„¶ãªæµã‚Œã§æ¬¡ã®è³ªå•ã‚’1ã¤ã ã‘ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        å‰ç½®ãã¯ä¸è¦ã§ã€è³ªå•ã ã‘ã‚’ç°¡æ½”ã«ã€‚"""
            
        # å®Ÿéš›ã®AIå‘¼ã³å‡ºã—å‡¦ç†
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": prompt
                    },
                    {
                        "role": "user", 
                        "content": user_last_message
                    }
                ],
                temperature=0.7,
                max_tokens=200
            )
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"âŒ è³ªå•ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è³ªå•
            fallback_questions = {
                1: "ã‚ãªãŸã«ã¨ã£ã¦ç†æƒ³ã®è·å ´ç’°å¢ƒã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚",
                2: "ã©ã®ã‚ˆã†ãªãƒãƒ¼ãƒ ã¨åƒããŸã„ã§ã™ã‹ï¼Ÿ",
                3: "è·å ´ã§é‡è¦–ã™ã‚‹ã“ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
                4: "ã©ã®ã‚ˆã†ãªæˆé•·æ©Ÿä¼šã‚’æ±‚ã‚ã¦ã„ã¾ã™ã‹ï¼Ÿ",
                5: "åƒãæ–¹ã§å¦¥å”ã§ããªã„ã“ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ"
            }
            return fallback_questions.get(min(conversation_turn, 5), "ã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ãã ã•ã„ã€‚")
    
    def _get_user_profile(self, user_id: int) -> Dict[str, Any]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—"""
        try:
            conn = get_db_conn()
            cur = conn.cursor(cursor_factory=RealDictCursor)
            
            cur.execute("""
                SELECT 
                    pd.user_name,
                    up.job_title,
                    up.location_prefecture,
                    up.salary_min
                FROM personal_date pd
                LEFT JOIN user_profile up ON pd.user_id = up.user_id
                WHERE pd.user_id = %s
            """, (user_id,))
            
            profile = cur.fetchone()
            cur.close()
            conn.close()
            
            return dict(profile) if profile else {}
            
        except Exception as e:
            print(f"âŒ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _get_conversation_history(
        self, 
        user_id: int, 
        session_id: str
    ) -> List[Dict[str, str]]:
        """ä¼šè©±å±¥æ­´å–å¾—"""
        try:
            conn = get_db_conn()
            cur = conn.cursor(cursor_factory=RealDictCursor)
            
            cur.execute("""
                SELECT sender, message
                FROM chat_history
                WHERE user_id = %s AND session_id = %s
                ORDER BY created_at
            """, (user_id, session_id))
            
            history = cur.fetchall()
            cur.close()
            conn.close()
            
            return [dict(h) for h in history]
            
        except Exception as e:
            print(f"âŒ ä¼šè©±å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _analyze_candidates(
        self, 
        candidates: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        å€™è£œæ±‚äººã®åˆ†å¸ƒã‚’åˆ†æ
        
        å€™è£œã®å¤šæ§˜æ€§ã‚’åˆ†æã—ã¦ã€ã©ã®é …ç›®ã«ã¤ã„ã¦è³ªå•ã™ã¹ãã‹åˆ¤æ–­
        """
        if not candidates:
            return {'has_diversity': False}
        
        analysis = {
            'total_count': len(candidates),
            'remote_work': {'full': 0, 'partial': 0, 'none': 0},
            'company_culture': {},
            'work_flexibility': {},
            'diversity_areas': []
        }
        
        # ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã®åˆ†å¸ƒ
        for job in candidates:
            remote = job.get('remote_work', 'none')
            if remote == 'full':
                analysis['remote_work']['full'] += 1
            elif remote == 'partial':
                analysis['remote_work']['partial'] += 1
            else:
                analysis['remote_work']['none'] += 1
        
        # å¤šæ§˜æ€§ãƒã‚§ãƒƒã‚¯
        if analysis['remote_work']['full'] > 0 and analysis['remote_work']['none'] > 0:
            analysis['diversity_areas'].append({
                'topic': 'remote_work',
                'label': 'ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯',
                'description': f"å®Œå…¨ãƒªãƒ¢ãƒ¼ãƒˆ{analysis['remote_work']['full']}ä»¶ã€å‡ºç¤¾{analysis['remote_work']['none']}ä»¶"
            })
        
        # ä¼æ¥­æ–‡åŒ–ã®åˆ†å¸ƒï¼ˆjob_summaryã‹ã‚‰æ¨æ¸¬ï¼‰
        keywords = {
            'ãƒ•ãƒ©ãƒƒãƒˆ': 0,
            'ã‚¹ãƒ”ãƒ¼ãƒ‰æ„Ÿ': 0,
            'ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯': 0,
            'æŒ‘æˆ¦': 0
        }
        
        for job in candidates:
            summary = job.get('company_culture', '') or ''
            for keyword in keywords.keys():
                if keyword in summary:
                    keywords[keyword] += 1
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«å¤šæ§˜æ€§ãŒã‚ã‚Œã°è¿½åŠ 
        for keyword, count in keywords.items():
            if count > 0 and count < len(candidates):
                analysis['diversity_areas'].append({
                    'topic': 'culture',
                    'label': f'{keyword}ãªæ–‡åŒ–',
                    'description': f"{count}ä»¶ã®ä¼æ¥­ãŒ{keyword}ã‚’é‡è¦–"
                })
        
        analysis['has_diversity'] = len(analysis['diversity_areas']) > 0
        
        return analysis
    
    def _determine_conversation_phase(self, turn: int) -> str:
        """
        ä¼šè©±ãƒ•ã‚§ãƒ¼ã‚ºã‚’åˆ¤å®š
        
        Args:
            turn: ã‚¿ãƒ¼ãƒ³æ•°ï¼ˆ1-10ï¼‰
            
        Returns:
            ãƒ•ã‚§ãƒ¼ã‚º ('exploration', 'deepening', 'confirmation')
        """
        if turn <= 3:
            return 'exploration'  # æ¢ç´¢ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆåºƒãèãï¼‰
        elif turn <= 6:
            return 'deepening'    # æ·±æ˜ã‚Šãƒ•ã‚§ãƒ¼ã‚ºï¼ˆè©³ã—ãèãï¼‰
        else:
            return 'confirmation' # ç¢ºèªãƒ•ã‚§ãƒ¼ã‚ºï¼ˆå„ªå…ˆé †ä½ã‚’æ˜ç¢ºåŒ–ï¼‰
    
    def _generate_with_ai(
        self,
        user_profile: Dict[str, Any],
        conversation_history: List[Dict[str, str]],
        accumulated_insights: Dict[str, Any],
        candidates_analysis: Dict[str, Any],
        phase: str,
        conversation_turn: int,
        user_last_message: str
    ) -> str:
        """AIã§è³ªå•ã‚’ç”Ÿæˆ"""
        
        # ãƒ•ã‚§ãƒ¼ã‚ºã”ã¨ã®æŒ‡ç¤º
        phase_instructions = {
            'exploration': """
ã€æ¢ç´¢ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆä¼šè©±1-3å›ç›®ï¼‰ã€‘
- ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ãªè³ªå•ã‚’ã—ã¦ãã ã•ã„
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¾¡å€¤è¦³ã‚„å„ªå…ˆé †ä½ã‚’åºƒãç†è§£ã™ã‚‹
- YES/NOã§çµ‚ã‚ã‚‰ãªã„è³ªå•
- ç†ç”±ã‚„èƒŒæ™¯ã‚’èãè³ªå•

ä¾‹:
- ã€Œç†æƒ³ã®åƒãæ–¹ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€
- ã€Œã‚­ãƒ£ãƒªã‚¢ã§æœ€ã‚‚å¤§åˆ‡ã«ã—ã¦ã„ã‚‹ã“ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿã€
- ã€Œãã®ç†ç”±ã‚’è©³ã—ãæ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿã€
""",
            'deepening': """
ã€æ·±æ˜ã‚Šãƒ•ã‚§ãƒ¼ã‚ºï¼ˆä¼šè©±4-6å›ç›®ï¼‰ã€‘
- å‰å›ã®å›ç­”ã‚’æ·±æ˜ã‚Šã™ã‚‹è³ªå•
- å…·ä½“çš„ãªå¸Œæœ›ã‚’æ˜ç¢ºåŒ–ã™ã‚‹
- ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’ç¢ºèªã™ã‚‹è³ªå•
- **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ¬è³ªçš„ãªãƒ‹ãƒ¼ã‚ºã‚’ç†è§£ã—ã€ä»£æ›¿æ¡ˆã‚’ææ¡ˆã™ã‚‹**

ä¾‹:
- ã€Œãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã‚ªãƒ•ã‚£ã‚¹å‹¤å‹™ã€ã©ã¡ã‚‰ãŒã‚ˆã‚Šé‡è¦ã§ã™ã‹ï¼Ÿã€
- ã€Œå¹´åã¨åƒãã‚„ã™ã•ã€å„ªå…ˆé †ä½ã‚’ã¤ã‘ã‚‹ã¨ã—ãŸã‚‰ï¼Ÿã€
- ã€Œãã®æ¡ä»¶ã‚’æº€ãŸã™ãŸã‚ã«ã€ä»–ã®æ¡ä»¶ã¯å¦¥å”ã§ãã¾ã™ã‹ï¼Ÿã€
- ã€Œã€œãŒç†ç”±ãªã‚‰ã€â–³â–³ã¨ã„ã†é¸æŠè‚¢ã‚‚ã‚ã‚Šã¾ã™ãŒã€ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ï¼Ÿã€ï¼ˆä»£æ›¿æ¡ˆæç¤ºï¼‰

**ä»£æ›¿æ¡ˆã®ä¾‹:**
- æº€å“¡é›»è»ŠãŒå«Œ â†’ ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ OR ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ ï¼ˆ10æ™‚å‡ºç¤¾ï¼‰
- é•·æ™‚é–“é€šå‹¤ãŒå«Œ â†’ ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ OR è·å ´è¿‘ãã«å¼•ã£è¶Šã—å¯ã®ä¼æ¥­
- å¹´åã‚’ä¸Šã’ãŸã„ â†’ é«˜å¹´å OR ã‚¹ãƒˆãƒƒã‚¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ»è³ä¸å……å®Ÿ
""",
            'confirmation': """
ã€ç¢ºèªãƒ•ã‚§ãƒ¼ã‚ºï¼ˆä¼šè©±7-10å›ç›®ï¼‰ã€‘
- æœ€å„ªå…ˆæ¡ä»¶ã®æœ€çµ‚ç¢ºèª
- å…·ä½“çš„ãªé¸æŠè‚¢ã‚’æç¤ºã—ã¦é¸ã‚“ã§ã‚‚ã‚‰ã†
- è¿·ã£ã¦ã„ã‚‹ç‚¹ã‚’æ˜ç¢ºåŒ–

ä¾‹:
- ã€ŒAç¤¾ã¨Bç¤¾ã€ã©ã¡ã‚‰ã«ã‚ˆã‚Šé­…åŠ›ã‚’æ„Ÿã˜ã¾ã™ã‹ï¼Ÿã€
- ã€Œæœ€ã‚‚è­²ã‚Œãªã„æ¡ä»¶ã¯ä½•ã§ã™ã‹ï¼Ÿã€
- ã€Œã“ã‚Œã¾ã§ã®è©±ã‹ã‚‰ã€ã€œãŒé‡è¦ã ã¨ç†è§£ã—ã¾ã—ãŸãŒã€åˆã£ã¦ã„ã¾ã™ã‹ï¼Ÿã€
"""
        }
        
        # éå»ã®ä¼šè©±ã‚’æ•´å½¢
        history_text = ""
        if conversation_history:
            history_text = "\n".join([
                f"{'ãƒ¦ãƒ¼ã‚¶ãƒ¼' if h['sender'] == 'user' else 'AI'}: {h['message']}"
                for h in conversation_history[-6:]  # æœ€æ–°6ä»¶
            ])
        
        # è“„ç©ã•ã‚ŒãŸæƒ…å ±ã‚’æ•´å½¢
        insights_text = json.dumps(accumulated_insights, ensure_ascii=False, indent=2)
        
        # å€™è£œåˆ†æã‚’æ•´å½¢
        diversity_text = ""
        if candidates_analysis.get('has_diversity'):
            diversity_text = "\nã€å€™è£œã®å¤šæ§˜æ€§ã€‘\n"
            for area in candidates_analysis['diversity_areas'][:3]:
                diversity_text += f"- {area['label']}: {area['description']}\n"
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        prompt = f"""ã‚ãªãŸã¯å„ªç§€ãªã‚­ãƒ£ãƒªã‚¢ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ä¼šè©±ã‚’é€šã˜ã¦ã€æœ€é©ãªæ±‚äººã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã®è³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã€‘
- åå‰: {user_profile.get('user_name', 'ãƒ¦ãƒ¼ã‚¶ãƒ¼')}ã•ã‚“
- å¸Œæœ›è·ç¨®: {user_profile.get('job_title', 'æœªè¨­å®š')}
- å¸Œæœ›å‹¤å‹™åœ°: {user_profile.get('location_prefecture', 'æœªè¨­å®š')}
- å¸Œæœ›å¹´å: {user_profile.get('salary_min', 0)}ä¸‡å††ä»¥ä¸Š

ã€ä¼šè©±ã®é€²è¡ŒçŠ¶æ³ã€‘
- ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³: {conversation_turn}/10
- ãƒ•ã‚§ãƒ¼ã‚º: {phase}
- å€™è£œæ±‚äººæ•°: {candidates_analysis.get('total_count', 0)}ä»¶

ã€éå»ã®ä¼šè©±ï¼ˆæœ€æ–°6ä»¶ï¼‰ã€‘
{history_text if history_text else 'ï¼ˆã¾ã ä¼šè©±ãªã—ï¼‰'}

ã€ã“ã‚Œã¾ã§ã«æŠ½å‡ºã•ã‚ŒãŸæƒ…å ±ã€‘
{insights_text}

{diversity_text}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€å¾Œã®ç™ºè¨€ã€‘
{user_last_message if user_last_message else 'ï¼ˆåˆå›ï¼‰'}

{phase_instructions[phase]}

ã€é‡è¦ãªæ³¨æ„ç‚¹ã€‘
1. æ—¢ã«èã„ãŸå†…å®¹ã‚’ç¹°ã‚Šè¿”ã•ãªã„
2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€å¾Œã®ç™ºè¨€ã‚’è¸ã¾ãˆã¦æ·±æ˜ã‚Šã™ã‚‹
3. è‡ªç„¶ãªä¼šè©±ã®æµã‚Œã‚’ä¿ã¤
4. å…·ä½“çš„ã§ç­”ãˆã‚„ã™ã„è³ªå•ã«ã™ã‚‹
5. **è³ªå•ã®æœ€å¾Œã«å¿…ãšå›ç­”ä¾‹ã‚’2-3å€‹æç¤ºã™ã‚‹**

ã€è¿”ç­”å½¢å¼ã€‘
JSONå½¢å¼ã§ä»¥ä¸‹ã®ã‚ˆã†ã«è¿”ã—ã¦ãã ã•ã„:
{{
  "question_text": "è³ªå•æ–‡ï¼ˆ200æ–‡å­—ä»¥å†…ï¼‰",
  "examples": ["å›ç­”ä¾‹1", "å›ç­”ä¾‹2", "å›ç­”ä¾‹3"],
  "reasoning": "ã“ã®è³ªå•ã‚’ã™ã‚‹ç†ç”±"
}}

**è³ªå•æ–‡ã®æœ€å¾Œã«ã¯å¿…ãšä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ä¾‹ã‚’å«ã‚ã¦ãã ã•ã„:**
ã€Œï¼ˆä¾‹: ã€œã€ã€œã€ã€œãªã©ï¼‰ã€

**å›ç­”ä¾‹ã®ä½œã‚Šæ–¹:**
- å…·ä½“çš„ã§å®Ÿéš›ã«ç­”ãˆã‚„ã™ã„ä¾‹ã‚’æç¤º
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®çŠ¶æ³ã«å¿œã˜ãŸä¾‹ã‚’é¸ã¶
- 2-3å€‹ã®é¸æŠè‚¢ã‚’æç¤º

è³ªå•æ–‡ã®ã¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚å‰ç½®ãã‚„èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  # JSONå½¢å¼ã«å¯¾å¿œã—ãŸãƒ¢ãƒ‡ãƒ«
                messages=[
                    {
                        "role": "system",
                        "content": "ã‚ãªãŸã¯å„ªç§€ãªã‚­ãƒ£ãƒªã‚¢ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯„ã‚Šæ·»ã£ãŸè³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            question_text = result.get('question_text', '')
            
            print(f"ğŸ¤– ç”Ÿæˆã•ã‚ŒãŸè³ªå•: {question_text}")
            print(f"ğŸ“ ç†ç”±: {result.get('reasoning', '')}")
            
            return question_text
            
        except Exception as e:
            print(f"âŒ AIè³ªå•ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._get_fallback_question(conversation_turn)
    
    def _get_fallback_question(self, turn: int) -> str:
        """
        ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è³ªå•ï¼ˆAIãŒå¤±æ•—ã—ãŸæ™‚ï¼‰
        
        Args:
            turn: ã‚¿ãƒ¼ãƒ³æ•°
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è³ªå•æ–‡
        """
        fallback_questions = {
            1: "ç†æƒ³ã®åƒãæ–¹ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚ã©ã‚“ãªç’°å¢ƒã§åƒããŸã„ã§ã™ã‹ï¼Ÿ",
            2: "ãã®ç†ç”±ã‚’è©³ã—ãæ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ",
            3: "ä»•äº‹ã§æœ€ã‚‚å¤§åˆ‡ã«ã—ã¦ã„ã‚‹ã“ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            4: "ã‚­ãƒ£ãƒªã‚¢ã®ç›®æ¨™ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚",
            5: "åƒãä¸Šã§ã€è­²ã‚Œãªã„æ¡ä»¶ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            6: "ãƒãƒ¼ãƒ ã‚„çµ„ç¹”ã®é›°å›²æ°—ã§é‡è¦–ã™ã‚‹ã“ã¨ã¯ï¼Ÿ",
            7: "ã“ã‚Œã¾ã§ã®è©±ã‚’è¸ã¾ãˆã¦ã€æœ€å„ªå…ˆã®æ¡ä»¶ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            8: "ãã®æ¡ä»¶ã‚’æº€ãŸã™ãŸã‚ã«ã€ä»–ã®æ¡ä»¶ã¯å¦¥å”ã§ãã¾ã™ã‹ï¼Ÿ",
            9: "ç†æƒ³ã®ä¼æ¥­ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
            10: "æœ€å¾Œã«ã€ä»–ã«é‡è¦–ã™ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"
        }
        
        return fallback_questions.get(turn, "ä»–ã«é‡è¦–ã™ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ")


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# äº’æ›æ€§ã®ãŸã‚ã®æ—§ã‚¯ãƒ©ã‚¹åã‚¨ã‚¤ãƒªã‚¢ã‚¹
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class DynamicQuestionGenerator(EvolvingQuestionGenerator):
    """
    æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ã®äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹
    
    æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã§ DynamicQuestionGenerator ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã€
    ãã®ã¾ã¾å‹•ä½œã™ã‚‹ã‚ˆã†ã«ã™ã‚‹
    """
    pass


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def create_question_generator(openai_api_key: str) -> EvolvingQuestionGenerator:
    """
    è³ªå•ç”Ÿæˆå™¨ã‚’ä½œæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    
    Args:
        openai_api_key: OpenAI APIã‚­ãƒ¼
        
    Returns:
        è³ªå•ç”Ÿæˆå™¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    from openai import OpenAI
    client = OpenAI(api_key=openai_api_key)
    return EvolvingQuestionGenerator(client)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

if __name__ == "__main__":
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
    test_user_id = 1
    test_session_id = "test-session-123"
    test_turn = 1
    
    test_candidates = [
        {
            'job_id': 'job-1',
            'job_title': 'Webãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼',
            'company_name': 'ãƒ†ã‚¹ãƒˆæ ªå¼ä¼šç¤¾',
            'remote_work': 'full',
            'company_culture': 'ãƒ•ãƒ©ãƒƒãƒˆãªçµ„ç¹”'
        },
        {
            'job_id': 'job-2',
            'job_title': 'UIãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼',
            'company_name': 'ã‚µãƒ³ãƒ—ãƒ«æ ªå¼ä¼šç¤¾',
            'remote_work': 'none',
            'company_culture': 'ã‚¹ãƒ”ãƒ¼ãƒ‰æ„Ÿã®ã‚ã‚‹ç’°å¢ƒ'
        }
    ]
    
    test_insights = {
        'explicit_preferences': {},
        'implicit_values': {},
        'pain_points': [],
        'keywords': []
    }
    
    # è³ªå•ç”Ÿæˆå™¨ã‚’ä½œæˆ
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        generator = create_question_generator(api_key)
        
        # è³ªå•ç”Ÿæˆ
        question = generator.generate_next_question(
            user_id=test_user_id,
            session_id=test_session_id,
            conversation_turn=test_turn,
            candidates=test_candidates,
            accumulated_insights=test_insights,
            user_last_message=""
        )
        
        print("\n" + "=" * 60)
        print("ğŸ¤– ç”Ÿæˆã•ã‚ŒãŸè³ªå•:")
        print("=" * 60)
        print(question)
        print("=" * 60)
    else:
        print("âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")